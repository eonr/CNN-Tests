{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flopkart.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "mVkmm-7-f8D-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Colab setup\n"
      ]
    },
    {
      "metadata": {
        "id": "uYHgxPiedr15",
        "colab_type": "code",
        "outputId": "e3884fa3-82a6-4057-c56b-f6b174aabf77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mfastai 1.0.42 has requirement torch>=1.0.0, but you'll have torch 0.4.0 which is incompatible.\u001b[0m\n",
            "0.4.0\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6WXSslxueGlC",
        "colab_type": "code",
        "outputId": "de66a403-efff-4d16-d02c-1b4dfbfd7d13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install Pillow==4.0.0\n",
        "!pip3 install PIL\n",
        "!pip3 install image"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Pillow==4.0.0\n",
            "  Using cached https://files.pythonhosted.org/packages/37/e8/b3fbf87b0188d22246678f8cd61e23e31caa1769ebc06f1664e2e5fe8a17/Pillow-4.0.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow==4.0.0) (0.46)\n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mfastai 1.0.42 has requirement torch>=1.0.0, but you'll have torch 0.4.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: Pillow\n",
            "  Found existing installation: Pillow 5.4.1\n",
            "    Uninstalling Pillow-5.4.1:\n",
            "      Successfully uninstalled Pillow-5.4.1\n",
            "Successfully installed Pillow-4.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting PIL\n",
            "\u001b[31m  Could not find a version that satisfies the requirement PIL (from versions: )\u001b[0m\n",
            "\u001b[31mNo matching distribution found for PIL\u001b[0m\n",
            "Requirement already satisfied: image in /usr/local/lib/python3.6/dist-packages (1.5.27)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from image) (4.0.0)\n",
            "Requirement already satisfied: django in /usr/local/lib/python3.6/dist-packages (from image) (2.1.5)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->image) (0.46)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from django->image) (2018.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SoXsPcEMuU_7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GeGopFioOivJ",
        "colab_type": "code",
        "outputId": "82a4081c-7ca2-4cdf-95e1-0b05bed849f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K    1% |▎                               | 10kB 24.1MB/s eta 0:00:01\r\u001b[K    2% |▋                               | 20kB 1.9MB/s eta 0:00:01\r\u001b[K    3% |█                               | 30kB 2.8MB/s eta 0:00:01\r\u001b[K    4% |█▎                              | 40kB 1.8MB/s eta 0:00:01\r\u001b[K    5% |█▋                              | 51kB 2.2MB/s eta 0:00:01\r\u001b[K    6% |██                              | 61kB 2.7MB/s eta 0:00:01\r\u001b[K    7% |██▎                             | 71kB 3.1MB/s eta 0:00:01\r\u001b[K    8% |██▋                             | 81kB 3.5MB/s eta 0:00:01\r\u001b[K    9% |███                             | 92kB 3.9MB/s eta 0:00:01\r\u001b[K    10% |███▎                            | 102kB 2.9MB/s eta 0:00:01\r\u001b[K    11% |███▋                            | 112kB 2.9MB/s eta 0:00:01\r\u001b[K    12% |████                            | 122kB 4.2MB/s eta 0:00:01\r\u001b[K    13% |████▎                           | 133kB 4.2MB/s eta 0:00:01\r\u001b[K    14% |████▋                           | 143kB 7.8MB/s eta 0:00:01\r\u001b[K    15% |█████                           | 153kB 7.8MB/s eta 0:00:01\r\u001b[K    16% |█████▎                          | 163kB 7.7MB/s eta 0:00:01\r\u001b[K    17% |█████▋                          | 174kB 7.7MB/s eta 0:00:01\r\u001b[K    18% |██████                          | 184kB 7.8MB/s eta 0:00:01\r\u001b[K    19% |██████▎                         | 194kB 7.7MB/s eta 0:00:01\r\u001b[K    20% |██████▋                         | 204kB 8.4MB/s eta 0:00:01\r\u001b[K    21% |███████                         | 215kB 8.4MB/s eta 0:00:01\r\u001b[K    22% |███████▎                        | 225kB 8.3MB/s eta 0:00:01\r\u001b[K    23% |███████▋                        | 235kB 8.5MB/s eta 0:00:01\r\u001b[K    24% |████████                        | 245kB 8.5MB/s eta 0:00:01\r\u001b[K    25% |████████▎                       | 256kB 8.5MB/s eta 0:00:01\r\u001b[K    26% |████████▋                       | 266kB 8.4MB/s eta 0:00:01\r\u001b[K    27% |█████████                       | 276kB 8.5MB/s eta 0:00:01\r\u001b[K    29% |█████████▎                      | 286kB 8.5MB/s eta 0:00:01\r\u001b[K    30% |█████████▋                      | 296kB 8.5MB/s eta 0:00:01\r\u001b[K    31% |██████████                      | 307kB 46.1MB/s eta 0:00:01\r\u001b[K    32% |██████████▎                     | 317kB 52.2MB/s eta 0:00:01\r\u001b[K    33% |██████████▋                     | 327kB 52.8MB/s eta 0:00:01\r\u001b[K    34% |███████████                     | 337kB 54.2MB/s eta 0:00:01\r\u001b[K    35% |███████████▎                    | 348kB 49.5MB/s eta 0:00:01\r\u001b[K    36% |███████████▋                    | 358kB 49.2MB/s eta 0:00:01\r\u001b[K    37% |████████████                    | 368kB 55.5MB/s eta 0:00:01\r\u001b[K    38% |████████████▎                   | 378kB 53.3MB/s eta 0:00:01\r\u001b[K    39% |████████████▋                   | 389kB 54.1MB/s eta 0:00:01\r\u001b[K    40% |█████████████                   | 399kB 10.6MB/s eta 0:00:01\r\u001b[K    41% |█████████████▎                  | 409kB 10.5MB/s eta 0:00:01\r\u001b[K    42% |█████████████▋                  | 419kB 10.5MB/s eta 0:00:01\r\u001b[K    43% |██████████████                  | 430kB 10.5MB/s eta 0:00:01\r\u001b[K    44% |██████████████▎                 | 440kB 10.4MB/s eta 0:00:01\r\u001b[K    45% |██████████████▋                 | 450kB 10.5MB/s eta 0:00:01\r\u001b[K    46% |███████████████                 | 460kB 10.4MB/s eta 0:00:01\r\u001b[K    47% |███████████████▎                | 471kB 10.4MB/s eta 0:00:01\r\u001b[K    48% |███████████████▋                | 481kB 10.5MB/s eta 0:00:01\r\u001b[K    49% |████████████████                | 491kB 10.4MB/s eta 0:00:01\r\u001b[K    50% |████████████████▎               | 501kB 49.9MB/s eta 0:00:01\r\u001b[K    51% |████████████████▋               | 512kB 47.8MB/s eta 0:00:01\r\u001b[K    52% |█████████████████               | 522kB 48.6MB/s eta 0:00:01\r\u001b[K    53% |█████████████████▎              | 532kB 49.6MB/s eta 0:00:01\r\u001b[K    54% |█████████████████▋              | 542kB 49.9MB/s eta 0:00:01\r\u001b[K    55% |██████████████████              | 552kB 54.5MB/s eta 0:00:01\r\u001b[K    57% |██████████████████▎             | 563kB 55.1MB/s eta 0:00:01\r\u001b[K    58% |██████████████████▋             | 573kB 54.5MB/s eta 0:00:01\r\u001b[K    59% |███████████████████             | 583kB 55.0MB/s eta 0:00:01\r\u001b[K    60% |███████████████████▎            | 593kB 54.5MB/s eta 0:00:01\r\u001b[K    61% |███████████████████▋            | 604kB 54.1MB/s eta 0:00:01\r\u001b[K    62% |████████████████████            | 614kB 60.6MB/s eta 0:00:01\r\u001b[K    63% |████████████████████▎           | 624kB 60.5MB/s eta 0:00:01\r\u001b[K    64% |████████████████████▋           | 634kB 61.0MB/s eta 0:00:01\r\u001b[K    65% |█████████████████████           | 645kB 61.6MB/s eta 0:00:01\r\u001b[K    66% |█████████████████████▎          | 655kB 61.2MB/s eta 0:00:01\r\u001b[K    67% |█████████████████████▋          | 665kB 48.8MB/s eta 0:00:01\r\u001b[K    68% |██████████████████████          | 675kB 48.7MB/s eta 0:00:01\r\u001b[K    69% |██████████████████████▎         | 686kB 48.7MB/s eta 0:00:01\r\u001b[K    70% |██████████████████████▋         | 696kB 49.3MB/s eta 0:00:01\r\u001b[K    71% |███████████████████████         | 706kB 48.9MB/s eta 0:00:01\r\u001b[K    72% |███████████████████████▎        | 716kB 49.3MB/s eta 0:00:01\r\u001b[K    73% |███████████████████████▋        | 727kB 48.3MB/s eta 0:00:01\r\u001b[K    74% |████████████████████████        | 737kB 48.4MB/s eta 0:00:01\r\u001b[K    75% |████████████████████████▎       | 747kB 48.7MB/s eta 0:00:01\r\u001b[K    76% |████████████████████████▋       | 757kB 14.1MB/s eta 0:00:01\r\u001b[K    77% |████████████████████████▉       | 768kB 15.0MB/s eta 0:00:01\r\u001b[K    78% |█████████████████████████▏      | 778kB 15.0MB/s eta 0:00:01\r\u001b[K    79% |█████████████████████████▌      | 788kB 15.0MB/s eta 0:00:01\r\u001b[K    80% |█████████████████████████▉      | 798kB 15.0MB/s eta 0:00:01\r\u001b[K    81% |██████████████████████████▏     | 808kB 15.0MB/s eta 0:00:01\r\u001b[K    82% |██████████████████████████▌     | 819kB 14.9MB/s eta 0:00:01\r\u001b[K    83% |██████████████████████████▉     | 829kB 15.0MB/s eta 0:00:01\r\u001b[K    85% |███████████████████████████▏    | 839kB 15.0MB/s eta 0:00:01\r\u001b[K    86% |███████████████████████████▌    | 849kB 15.0MB/s eta 0:00:01\r\u001b[K    87% |███████████████████████████▉    | 860kB 55.1MB/s eta 0:00:01\r\u001b[K    88% |████████████████████████████▏   | 870kB 54.9MB/s eta 0:00:01\r\u001b[K    89% |████████████████████████████▌   | 880kB 55.8MB/s eta 0:00:01\r\u001b[K    90% |████████████████████████████▉   | 890kB 55.8MB/s eta 0:00:01\r\u001b[K    91% |█████████████████████████████▏  | 901kB 55.3MB/s eta 0:00:01\r\u001b[K    92% |█████████████████████████████▌  | 911kB 56.5MB/s eta 0:00:01\r\u001b[K    93% |█████████████████████████████▉  | 921kB 56.3MB/s eta 0:00:01\r\u001b[K    94% |██████████████████████████████▏ | 931kB 56.5MB/s eta 0:00:01\r\u001b[K    95% |██████████████████████████████▌ | 942kB 57.2MB/s eta 0:00:01\r\u001b[K    96% |██████████████████████████████▉ | 952kB 55.1MB/s eta 0:00:01\r\u001b[K    97% |███████████████████████████████▏| 962kB 62.7MB/s eta 0:00:01\r\u001b[K    98% |███████████████████████████████▌| 972kB 63.4MB/s eta 0:00:01\r\u001b[K    99% |███████████████████████████████▉| 983kB 60.1MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 993kB 20.6MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25ldone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KlXv3fo-pvKg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xevPuBdENbdw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ]
    },
    {
      "metadata": {
        "id": "K55Z6esrFSeC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "downloaded = drive.CreateFile({'id': '1dvhJaM3kO5lzWlQprKIKgV6GRS4LqT5c'})\n",
        "downloaded.GetContentFile('train.zip')\n",
        "downloaded = drive.CreateFile({'id': '1rh6bJymqTsqMwBCRSBy67kteWQC3TKLr'})\n",
        "downloaded.GetContentFile('test.csv')\n",
        "downloaded = drive.CreateFile({'id': '16OwlhaHXsEB4d4dTmDJl_FDEabO9E6GQ'})\n",
        "downloaded.GetContentFile('training.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZNDT4Y8hJCYY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!rm -rf train_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7ZnoYXO-00yF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!unzip train.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t12s7Xe4Nff3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('training.csv')\n",
        "#train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q3oDBUFRHA1W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Shuffling dataset\n",
        "from sklearn.utils import shuffle\n",
        "train = shuffle(train)\n",
        "train = train.reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y9M_z9wf9bWz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#train[:32*120]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nanjvm4l-aOd",
        "colab_type": "code",
        "outputId": "e211a05b-d0ad-4819-a355-ab713da73ea9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>y1</th>\n",
              "      <th>y2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train11575</td>\n",
              "      <td>104</td>\n",
              "      <td>560</td>\n",
              "      <td>126</td>\n",
              "      <td>312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train7126</td>\n",
              "      <td>0</td>\n",
              "      <td>640</td>\n",
              "      <td>0</td>\n",
              "      <td>480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train10399</td>\n",
              "      <td>212</td>\n",
              "      <td>427</td>\n",
              "      <td>83</td>\n",
              "      <td>457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train13723</td>\n",
              "      <td>122</td>\n",
              "      <td>487</td>\n",
              "      <td>32</td>\n",
              "      <td>460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train4011</td>\n",
              "      <td>82</td>\n",
              "      <td>617</td>\n",
              "      <td>66</td>\n",
              "      <td>435</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   image_name   x1   x2   y1   y2\n",
              "0  train11575  104  560  126  312\n",
              "1   train7126    0  640    0  480\n",
              "2  train10399  212  427   83  457\n",
              "3  train13723  122  487   32  460\n",
              "4   train4011   82  617   66  435"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "metadata": {
        "id": "Oo0cE-v7-Wj3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Putting labels in a torch tensor and reshaping to (size x 4) + normalizing\n",
        "train_labels = torch.tensor(([(train['x1']/640).tolist(),(train['x2']/640).tolist(),(train['y1']/480).tolist(),(train['y2']/480).tolist()]))\n",
        "train_labels = torch.transpose(train_labels,0,1)\n",
        "#train_labels = train_labels-0.5\n",
        "train_names = train['image_name']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_7H4gVc9HBAf",
        "colab_type": "code",
        "outputId": "e08db656-c929-45f4-d31b-d40994571df9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "print('Sample lables')\n",
        "print(train_labels[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample lables\n",
            "tensor([[ 0.1625,  0.8750,  0.2625,  0.6500],\n",
            "        [ 0.0000,  1.0000,  0.0000,  1.0000],\n",
            "        [ 0.3313,  0.6672,  0.1729,  0.9521],\n",
            "        [ 0.1906,  0.7609,  0.0667,  0.9583],\n",
            "        [ 0.1281,  0.9641,  0.1375,  0.9062],\n",
            "        [ 0.0766,  0.9578,  0.1729,  0.8687],\n",
            "        [ 0.0938,  0.8781,  0.2604,  0.7500],\n",
            "        [ 0.0000,  0.7937,  0.0312,  0.9104],\n",
            "        [ 0.0922,  0.8953,  0.3208,  0.7042],\n",
            "        [ 0.3031,  0.6594,  0.2667,  0.7958]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NIgRM-ucwzPr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tfms = transforms.Compose([transforms.Resize((224,224)),transforms.transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aTFCdyDnykS6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def getImage(name):\n",
        "  \"\"\"\n",
        "  Returns image specified by the name as torch.tensor\"\"\"\n",
        "  img_name = os.path.join(\"/content/train_images/\", name)\n",
        "  image = Image.open(img_name)\n",
        "  if tfms:\n",
        "    image = tfms(image)\n",
        "  return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6kbqPO4rB8IV",
        "colab_type": "code",
        "outputId": "2312a0de-dbe9-458b-b3e6-df40f7ac8340",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print('Size of input image:',getImage('train0').shape)\n",
        "# I checked, all images are of the same size (480, 640) originally"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of input image: torch.Size([3, 224, 224])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CozkOmrcghJq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model"
      ]
    },
    {
      "metadata": {
        "id": "fb6aWo-hKAus",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.count = 0\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv1 = nn.Conv2d(3, 32,3)\n",
        "        #pool\n",
        "        self.conv2 = nn.Conv2d(32, 32, 3)\n",
        "        #pool\n",
        "        self.conv3 = nn.Conv2d(32,32,3)\n",
        "        #pool\n",
        "        self.conv4 = nn.Conv2d(32,32,3)        \n",
        "        #pool\n",
        "        self.conv5 = nn.Conv2d(32,64,3)\n",
        "        #pool\n",
        "        self.conv6 = nn.Conv2d(64,64,3)\n",
        "        self.conv7 = nn.Conv2d(64,64,3)\n",
        "        #pool\n",
        "        self.bnorm128 = nn.BatchNorm2d(64)\n",
        "        self.bnorm32 = nn.BatchNorm2d(32)\n",
        "        self.b1d = nn.BatchNorm1d(4)\n",
        "        self.fc1 = nn.Linear(1792, 4)  #4*7*64\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.count += 1\n",
        "        x = (F.relu(self.conv1(x)))\n",
        "        x = self.pool(x)\n",
        "        x = (F.relu(self.conv2(x)))\n",
        "        x = self.pool(x)\n",
        "        #x = F.dropout(x,p=0.3)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool(x)\n",
        "        #x = self.bnorm32(x)\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.pool(x)\n",
        "        #x = F.dropout(x,p=0.3)\n",
        "        x = (F.relu(self.conv5(x)))\n",
        "        x = self.pool(x)\n",
        "        x = (F.relu(self.conv6(x)))\n",
        "        #x = self.bnorm128(x)\n",
        "        x = (F.relu(self.conv7(x)))\n",
        "        x = self.pool(x)\n",
        "        #print(x.shape)\n",
        "        x = x.view(-1, 1792) #Batch_size x 1792\n",
        "        x = self.fc1(x) #Batch_size x 4\n",
        "        #x = self.b1d(x)\n",
        "        if(self.count%32==0):\n",
        "          print(x)\n",
        "        #x = F.sigmoid(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nEOlgPMXymHl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        #print(input.shape)\n",
        "        p = input.view(input.size(0), -1)\n",
        "        return (p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I4m8nfHduUKc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Hyperparameters\n",
        "NUM_EPOCHS = 10\n",
        "LR = (5*1e-3)\n",
        "BATCH_SIZE = 32\n",
        "GAMMA = 0.6 #LR Decay\n",
        "curr_lr = LR\n",
        "WD = 1e-5\n",
        "MOMENTUM = 0.9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7Hc35Ctoy0Lp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = models.resnet34(pretrained=True)\n",
        "\n",
        "model = nn.Sequential(*list(model.children())[:-2],\n",
        "                    # nn.Dropout(),\n",
        "                     nn.Conv2d(512, 32, 3),\n",
        "                     nn.ReLU(),Flatten(),\n",
        "                     nn.Linear(800,4))\n",
        "\n",
        "#model = Net()\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=WD)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fJmS7JTcCRH0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once in a notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Create & upload a text file.\n",
        "uploaded = drive.CreateFile({'title': 'Sample file.txt'})\n",
        "uploaded.SetContentString('Sample upload file content')\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r28TqwORzkAH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#print(model.children)\n",
        "#Freezing early layers\n",
        "count = 0\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "    count += 1\n",
        "    if count >=7 :\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-7qSJsvyzrrc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def adjust_learning_rate(optimizer, lr):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mRWXuRh6gkhj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training"
      ]
    },
    {
      "metadata": {
        "id": "9mkcWkLQM_qI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "accuracies = []\n",
        "validation_accuracies=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_D2sey4b6ax9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def validation_accuracy(model):\n",
        "  \"\"\"\n",
        "  Performs inference on the Validation set and returns the reported accuracy\n",
        "  \"\"\"\n",
        "  correct = 0\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for idx in range(0,99):\n",
        "      data = getitem(test_indexes[idx])\n",
        "      image = data['image']\n",
        "      exp = data['category']\n",
        "      image = image.unsqueeze(0).cuda()\n",
        "      target = model(image)\n",
        "      ans = (torch.argmax(target).cpu().numpy()+1)\n",
        "      if (ans == exp):\n",
        "        correct +=1\n",
        "  return (correct/99)\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ntHZzQ2eztpf",
        "colab_type": "code",
        "outputId": "5a5a00f7-5732-4097-ba9e-781d8438ff7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4382
        }
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    #accuracy = 0\n",
        "    #count = 0\n",
        "    curr_lr *= GAMMA\n",
        "    adjust_learning_rate(optimizer, curr_lr)\n",
        "  \n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    for c in range(0,int(len(train)/BATCH_SIZE)):\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        #if (c==100):\n",
        "        #  torch.save(model.state_dict(), \"model_at_100epoch_\"+str(epoch)+\"pt\")\n",
        "          #curr_lr *= GAMMA\n",
        "          #adjust_learning_rate(optimizer, curr_lr)\n",
        "        \n",
        "        images = torch.zeros([BATCH_SIZE,3,224,224])\n",
        "        for p in range(0,BATCH_SIZE):\n",
        "            images[p,:,:,:] = getImage(train_names[c*BATCH_SIZE+p])\n",
        "        \n",
        "        targets = train_labels[c*BATCH_SIZE:(c+1)*BATCH_SIZE]\n",
        "        targets = targets.float()\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            images = images.cuda()\n",
        "            targets = targets.cuda()\n",
        "        \n",
        "        outs = model(images)\n",
        "        #print(outs.shape)\n",
        "        loss = criterion(outs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "                \n",
        "        total_loss += loss.data\n",
        "        #accuracy += torch.sum(torch.argmax(outs, dim=1) == targets)\n",
        "        #count += 1\n",
        "\n",
        "        if c%10 == 0:\n",
        "            print(\"Epoch:\", epoch, \"Iter:\", c, \"average batch loss:\", total_loss/(c+1))\n",
        "    \n",
        "    \n",
        "    #print(\"\\nEpoch:\", epoch, \"Total loss:\", total_loss)\n",
        "    #acc = accuracy.cpu().numpy()/(count*BATCH_SIZE)\n",
        "    #print(\"Epoch:\", epoch, \"Accuracy:\", acc,'\\n') \n",
        "    \n",
        "    #model.eval()\n",
        "    #val_acc = validation_accuracy(model)\n",
        "    #print('Validation accuracy:',val_acc)\n",
        "    #model.train()\n",
        "    \n",
        "    torch.save(model.state_dict(), \"model_at_epoch_\"+str(epoch)+\"pt\")\n",
        "    losses.append(total_loss)\n",
        "    #accuracies.append(acc)\n",
        "    #validation_accuracies.append(val_acc)\n",
        "    #validation_losses.append(val_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Iter: 0 average batch loss: tensor(0.6173, device='cuda:0')\n",
            "Epoch: 0 Iter: 10 average batch loss: tensor(0.1692, device='cuda:0')\n",
            "Epoch: 0 Iter: 20 average batch loss: tensor(0.1109, device='cuda:0')\n",
            "Epoch: 0 Iter: 30 average batch loss: tensor(1.00000e-02 *\n",
            "       8.3529, device='cuda:0')\n",
            "Epoch: 0 Iter: 40 average batch loss: tensor(1.00000e-02 *\n",
            "       6.7296, device='cuda:0')\n",
            "Epoch: 0 Iter: 50 average batch loss: tensor(1.00000e-02 *\n",
            "       5.6916, device='cuda:0')\n",
            "Epoch: 0 Iter: 60 average batch loss: tensor(1.00000e-02 *\n",
            "       4.9669, device='cuda:0')\n",
            "Epoch: 0 Iter: 70 average batch loss: tensor(1.00000e-02 *\n",
            "       4.4251, device='cuda:0')\n",
            "Epoch: 0 Iter: 80 average batch loss: tensor(1.00000e-02 *\n",
            "       4.0250, device='cuda:0')\n",
            "Epoch: 0 Iter: 90 average batch loss: tensor(1.00000e-02 *\n",
            "       3.7024, device='cuda:0')\n",
            "Epoch: 0 Iter: 100 average batch loss: tensor(1.00000e-02 *\n",
            "       3.4334, device='cuda:0')\n",
            "Epoch: 0 Iter: 110 average batch loss: tensor(1.00000e-02 *\n",
            "       3.1982, device='cuda:0')\n",
            "Epoch: 0 Iter: 120 average batch loss: tensor(1.00000e-02 *\n",
            "       3.0111, device='cuda:0')\n",
            "Epoch: 0 Iter: 130 average batch loss: tensor(1.00000e-02 *\n",
            "       2.8501, device='cuda:0')\n",
            "Epoch: 0 Iter: 140 average batch loss: tensor(1.00000e-02 *\n",
            "       2.6992, device='cuda:0')\n",
            "Epoch: 0 Iter: 150 average batch loss: tensor(1.00000e-02 *\n",
            "       2.5705, device='cuda:0')\n",
            "Epoch: 0 Iter: 160 average batch loss: tensor(1.00000e-02 *\n",
            "       2.4615, device='cuda:0')\n",
            "Epoch: 0 Iter: 170 average batch loss: tensor(1.00000e-02 *\n",
            "       2.3663, device='cuda:0')\n",
            "Epoch: 0 Iter: 180 average batch loss: tensor(1.00000e-02 *\n",
            "       2.2810, device='cuda:0')\n",
            "Epoch: 0 Iter: 190 average batch loss: tensor(1.00000e-02 *\n",
            "       2.2040, device='cuda:0')\n",
            "Epoch: 0 Iter: 200 average batch loss: tensor(1.00000e-02 *\n",
            "       2.1340, device='cuda:0')\n",
            "Epoch: 0 Iter: 210 average batch loss: tensor(1.00000e-02 *\n",
            "       2.0707, device='cuda:0')\n",
            "Epoch: 0 Iter: 220 average batch loss: tensor(1.00000e-02 *\n",
            "       2.0186, device='cuda:0')\n",
            "Epoch: 0 Iter: 230 average batch loss: tensor(1.00000e-02 *\n",
            "       1.9656, device='cuda:0')\n",
            "Epoch: 0 Iter: 240 average batch loss: tensor(1.00000e-02 *\n",
            "       1.9101, device='cuda:0')\n",
            "Epoch: 0 Iter: 250 average batch loss: tensor(1.00000e-02 *\n",
            "       1.8617, device='cuda:0')\n",
            "Epoch: 0 Iter: 260 average batch loss: tensor(1.00000e-02 *\n",
            "       1.8170, device='cuda:0')\n",
            "Epoch: 0 Iter: 270 average batch loss: tensor(1.00000e-02 *\n",
            "       1.7752, device='cuda:0')\n",
            "Epoch: 0 Iter: 280 average batch loss: tensor(1.00000e-02 *\n",
            "       1.7351, device='cuda:0')\n",
            "Epoch: 0 Iter: 290 average batch loss: tensor(1.00000e-02 *\n",
            "       1.6971, device='cuda:0')\n",
            "Epoch: 0 Iter: 300 average batch loss: tensor(1.00000e-02 *\n",
            "       1.6620, device='cuda:0')\n",
            "Epoch: 0 Iter: 310 average batch loss: tensor(1.00000e-02 *\n",
            "       1.6306, device='cuda:0')\n",
            "Epoch: 0 Iter: 320 average batch loss: tensor(1.00000e-02 *\n",
            "       1.5964, device='cuda:0')\n",
            "Epoch: 0 Iter: 330 average batch loss: tensor(1.00000e-02 *\n",
            "       1.5654, device='cuda:0')\n",
            "Epoch: 0 Iter: 340 average batch loss: tensor(1.00000e-02 *\n",
            "       1.5355, device='cuda:0')\n",
            "Epoch: 0 Iter: 350 average batch loss: tensor(1.00000e-02 *\n",
            "       1.5088, device='cuda:0')\n",
            "Epoch: 0 Iter: 360 average batch loss: tensor(1.00000e-02 *\n",
            "       1.4832, device='cuda:0')\n",
            "Epoch: 0 Iter: 370 average batch loss: tensor(1.00000e-02 *\n",
            "       1.4600, device='cuda:0')\n",
            "Epoch: 0 Iter: 380 average batch loss: tensor(1.00000e-02 *\n",
            "       1.4396, device='cuda:0')\n",
            "Epoch: 0 Iter: 390 average batch loss: tensor(1.00000e-02 *\n",
            "       1.4206, device='cuda:0')\n",
            "Epoch: 0 Iter: 400 average batch loss: tensor(1.00000e-02 *\n",
            "       1.3994, device='cuda:0')\n",
            "Epoch: 0 Iter: 410 average batch loss: tensor(1.00000e-02 *\n",
            "       1.3803, device='cuda:0')\n",
            "Epoch: 0 Iter: 420 average batch loss: tensor(1.00000e-02 *\n",
            "       1.3601, device='cuda:0')\n",
            "Epoch: 0 Iter: 430 average batch loss: tensor(1.00000e-02 *\n",
            "       1.3406, device='cuda:0')\n",
            "Epoch: 1 Iter: 0 average batch loss: tensor(1.00000e-02 *\n",
            "       1.4322, device='cuda:0')\n",
            "Epoch: 1 Iter: 10 average batch loss: tensor(1.00000e-03 *\n",
            "       6.5788, device='cuda:0')\n",
            "Epoch: 1 Iter: 20 average batch loss: tensor(1.00000e-03 *\n",
            "       6.2132, device='cuda:0')\n",
            "Epoch: 1 Iter: 30 average batch loss: tensor(1.00000e-03 *\n",
            "       5.9205, device='cuda:0')\n",
            "Epoch: 1 Iter: 40 average batch loss: tensor(1.00000e-03 *\n",
            "       5.6215, device='cuda:0')\n",
            "Epoch: 1 Iter: 50 average batch loss: tensor(1.00000e-03 *\n",
            "       5.4125, device='cuda:0')\n",
            "Epoch: 1 Iter: 60 average batch loss: tensor(1.00000e-03 *\n",
            "       5.3830, device='cuda:0')\n",
            "Epoch: 1 Iter: 70 average batch loss: tensor(1.00000e-03 *\n",
            "       5.3812, device='cuda:0')\n",
            "Epoch: 1 Iter: 80 average batch loss: tensor(1.00000e-03 *\n",
            "       5.4973, device='cuda:0')\n",
            "Epoch: 1 Iter: 90 average batch loss: tensor(1.00000e-03 *\n",
            "       5.4403, device='cuda:0')\n",
            "Epoch: 1 Iter: 100 average batch loss: tensor(1.00000e-03 *\n",
            "       5.3251, device='cuda:0')\n",
            "Epoch: 1 Iter: 110 average batch loss: tensor(1.00000e-03 *\n",
            "       5.2488, device='cuda:0')\n",
            "Epoch: 1 Iter: 120 average batch loss: tensor(1.00000e-03 *\n",
            "       5.2347, device='cuda:0')\n",
            "Epoch: 1 Iter: 130 average batch loss: tensor(1.00000e-03 *\n",
            "       5.2516, device='cuda:0')\n",
            "Epoch: 1 Iter: 140 average batch loss: tensor(1.00000e-03 *\n",
            "       5.1682, device='cuda:0')\n",
            "Epoch: 1 Iter: 150 average batch loss: tensor(1.00000e-03 *\n",
            "       5.1369, device='cuda:0')\n",
            "Epoch: 1 Iter: 160 average batch loss: tensor(1.00000e-03 *\n",
            "       5.1219, device='cuda:0')\n",
            "Epoch: 1 Iter: 170 average batch loss: tensor(1.00000e-03 *\n",
            "       5.1349, device='cuda:0')\n",
            "Epoch: 1 Iter: 180 average batch loss: tensor(1.00000e-03 *\n",
            "       5.1215, device='cuda:0')\n",
            "Epoch: 1 Iter: 190 average batch loss: tensor(1.00000e-03 *\n",
            "       5.0749, device='cuda:0')\n",
            "Epoch: 1 Iter: 200 average batch loss: tensor(1.00000e-03 *\n",
            "       5.0333, device='cuda:0')\n",
            "Epoch: 1 Iter: 210 average batch loss: tensor(1.00000e-03 *\n",
            "       5.0031, device='cuda:0')\n",
            "Epoch: 1 Iter: 220 average batch loss: tensor(1.00000e-03 *\n",
            "       5.0259, device='cuda:0')\n",
            "Epoch: 1 Iter: 230 average batch loss: tensor(1.00000e-03 *\n",
            "       5.0347, device='cuda:0')\n",
            "Epoch: 1 Iter: 240 average batch loss: tensor(1.00000e-03 *\n",
            "       5.0009, device='cuda:0')\n",
            "Epoch: 1 Iter: 250 average batch loss: tensor(1.00000e-03 *\n",
            "       4.9969, device='cuda:0')\n",
            "Epoch: 1 Iter: 260 average batch loss: tensor(1.00000e-03 *\n",
            "       4.9633, device='cuda:0')\n",
            "Epoch: 1 Iter: 270 average batch loss: tensor(1.00000e-03 *\n",
            "       4.9556, device='cuda:0')\n",
            "Epoch: 1 Iter: 280 average batch loss: tensor(1.00000e-03 *\n",
            "       4.9272, device='cuda:0')\n",
            "Epoch: 1 Iter: 290 average batch loss: tensor(1.00000e-03 *\n",
            "       4.9003, device='cuda:0')\n",
            "Epoch: 1 Iter: 300 average batch loss: tensor(1.00000e-03 *\n",
            "       4.8760, device='cuda:0')\n",
            "Epoch: 1 Iter: 310 average batch loss: tensor(1.00000e-03 *\n",
            "       4.8731, device='cuda:0')\n",
            "Epoch: 1 Iter: 320 average batch loss: tensor(1.00000e-03 *\n",
            "       4.8509, device='cuda:0')\n",
            "Epoch: 1 Iter: 330 average batch loss: tensor(1.00000e-03 *\n",
            "       4.8506, device='cuda:0')\n",
            "Epoch: 1 Iter: 340 average batch loss: tensor(1.00000e-03 *\n",
            "       4.8364, device='cuda:0')\n",
            "Epoch: 1 Iter: 350 average batch loss: tensor(1.00000e-03 *\n",
            "       4.8325, device='cuda:0')\n",
            "Epoch: 1 Iter: 360 average batch loss: tensor(1.00000e-03 *\n",
            "       4.8226, device='cuda:0')\n",
            "Epoch: 1 Iter: 370 average batch loss: tensor(1.00000e-03 *\n",
            "       4.8136, device='cuda:0')\n",
            "Epoch: 1 Iter: 380 average batch loss: tensor(1.00000e-03 *\n",
            "       4.8182, device='cuda:0')\n",
            "Epoch: 1 Iter: 390 average batch loss: tensor(1.00000e-03 *\n",
            "       4.8227, device='cuda:0')\n",
            "Epoch: 1 Iter: 400 average batch loss: tensor(1.00000e-03 *\n",
            "       4.8072, device='cuda:0')\n",
            "Epoch: 1 Iter: 410 average batch loss: tensor(1.00000e-03 *\n",
            "       4.8144, device='cuda:0')\n",
            "Epoch: 1 Iter: 420 average batch loss: tensor(1.00000e-03 *\n",
            "       4.8009, device='cuda:0')\n",
            "Epoch: 1 Iter: 430 average batch loss: tensor(1.00000e-03 *\n",
            "       4.7780, device='cuda:0')\n",
            "Epoch: 2 Iter: 0 average batch loss: tensor(1.00000e-02 *\n",
            "       1.2770, device='cuda:0')\n",
            "Epoch: 2 Iter: 10 average batch loss: tensor(1.00000e-03 *\n",
            "       5.4966, device='cuda:0')\n",
            "Epoch: 2 Iter: 20 average batch loss: tensor(1.00000e-03 *\n",
            "       4.9332, device='cuda:0')\n",
            "Epoch: 2 Iter: 30 average batch loss: tensor(1.00000e-03 *\n",
            "       4.6376, device='cuda:0')\n",
            "Epoch: 2 Iter: 40 average batch loss: tensor(1.00000e-03 *\n",
            "       4.4016, device='cuda:0')\n",
            "Epoch: 2 Iter: 50 average batch loss: tensor(1.00000e-03 *\n",
            "       4.3847, device='cuda:0')\n",
            "Epoch: 2 Iter: 60 average batch loss: tensor(1.00000e-03 *\n",
            "       4.4124, device='cuda:0')\n",
            "Epoch: 2 Iter: 70 average batch loss: tensor(1.00000e-03 *\n",
            "       4.3893, device='cuda:0')\n",
            "Epoch: 2 Iter: 80 average batch loss: tensor(1.00000e-03 *\n",
            "       4.4077, device='cuda:0')\n",
            "Epoch: 2 Iter: 90 average batch loss: tensor(1.00000e-03 *\n",
            "       4.3322, device='cuda:0')\n",
            "Epoch: 2 Iter: 100 average batch loss: tensor(1.00000e-03 *\n",
            "       4.2493, device='cuda:0')\n",
            "Epoch: 2 Iter: 110 average batch loss: tensor(1.00000e-03 *\n",
            "       4.1992, device='cuda:0')\n",
            "Epoch: 2 Iter: 120 average batch loss: tensor(1.00000e-03 *\n",
            "       4.1733, device='cuda:0')\n",
            "Epoch: 2 Iter: 130 average batch loss: tensor(1.00000e-03 *\n",
            "       4.1724, device='cuda:0')\n",
            "Epoch: 2 Iter: 140 average batch loss: tensor(1.00000e-03 *\n",
            "       4.1161, device='cuda:0')\n",
            "Epoch: 2 Iter: 150 average batch loss: tensor(1.00000e-03 *\n",
            "       4.1137, device='cuda:0')\n",
            "Epoch: 2 Iter: 160 average batch loss: tensor(1.00000e-03 *\n",
            "       4.1145, device='cuda:0')\n",
            "Epoch: 2 Iter: 170 average batch loss: tensor(1.00000e-03 *\n",
            "       4.1386, device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-188-c05d0e5427cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-76-3d71199a1faa>\u001b[0m in \u001b[0;36mgetImage\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtfms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \"\"\"\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample)\u001b[0m\n\u001b[1;32m   1554\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGBa'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGBA'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1556\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1558\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNEAREST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "BaxWNCbFIy_K",
        "colab_type": "code",
        "outputId": "7240c412-a473-4aff-b32c-414b0fa31dcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(losses)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAFYCAYAAABUA1WSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAGbhJREFUeJzt3X9M1ff1x/HXBURFL8hduKjTZM7V\nmTn8QUQTScAtYjNnmlS9ApYty2xsM5dMQ13RrcNNYeKv1ShObXUljilgaWfMpl1TnGbc6VoSMJhl\najKFOOXeCeIFG0A/3z9Mb79Mi8iFe7nv+3z8d3nfyz33tMmT+7mKNsuyLAEAAGNFhXoAAAAwtIg9\nAACGI/YAABiO2AMAYDhiDwCA4Yg9AACGiwn1AEPF47kX6hGCLjExTq2tnaEeI6yxw8Cxw8Cxw8BF\n4g6TkuxfeMY7e4PExESHeoSwxw4Dxw4Dxw4Dxw57I/YAABiO2AMAYDhiDwCA4Yg9AACGI/YAABiO\n2AMAYDhiDwCA4Yg9AACGI/YAABiO2AMAYDhiDwCA4Yg9AACGI/YAABiO2AMAYDhiDwCA4Yg9AACG\nI/YAABiO2AMAYDhiDwCA4Yg9AACGI/YAABiO2AMAYDhiDwCA4Yg9AACGI/YAABiO2AMAYDhiDwCA\n4Yg9AACGI/YAABiO2AMAYDhiDwCA4Yg9AACGI/YAABiO2AMAYDhiDwCA4YIe++LiYmVnZysnJ0cN\nDQ29zmpra7VixQplZ2ertLS019mnn36qRYsWqbq6OpjjAgAQ9oIa+4sXL+r69euqqKhQUVGRioqK\nep1v3bpVe/fu1bFjx/S3v/1NV69e9Z/99re/VUJCQjDHBQDACEGNvdvt1qJFiyRJU6dO1d27d+Xz\n+SRJTU1NSkhI0IQJExQVFaXMzEy53W5J0rVr13T16lUtXLgwmOMCAGCEoMbe6/UqMTHRf9vhcMjj\n8UiSPB6PHA7HE89KSkpUUFAQzFEBADBGTCif3LKsp97n/fff1+zZszV58uRn+t6JiXGKiYke6Ghh\nKynJHuoRwh47DBw7DBw7DBw7/FxQY+90OuX1ev23W1palJSU9MSz27dvy+l06uzZs2pqatLZs2d1\n69YtxcbGavz48VqwYEGfz9Xa2jk0L2IYS0qyy+O5F+oxwho7DBw7DBw7DFwk7rCvH26CGvv09HTt\n3btXOTk5amxslNPp1NixYyVJkyZNks/nU3Nzs8aPH6+amhrt3LlTeXl5/sfv3btXX/7yl58aegAA\n8Lmgxj41NVUzZsxQTk6ObDabCgsLVV1dLbvdrqysLG3evFn5+fmSpCVLlmjKlCnBHA8AACPZrP58\ncB6GIu3yjRSZl60GGzsMHDsMHDsMXCTusK/L+PwGPQAADEfsAQAwHLEHAMBwxB4AAMMRewAADEfs\nAQAwHLEHAMBwxB4AAMMRewAADEfsAQAwHLEHAMBwxB4AAMMRewAADEfsAQAwHLEHAMBwxB4AAMMR\newAADEfsAQAwHLEHAMBwxB4AAMMRewAADEfsAQAwHLEHAMBwxB4AAMMRewAADEfsAQAwHLEHAMBw\nxB4AAMMRewAADEfsAQAwHLEHAMBwxB4AAMMRewAADEfsAQAwHLEHAMBwxB4AAMMRewAADEfsAQAw\nHLEHAMBwxB4AAMMRewAADEfsAQAwHLEHAMBwxB4AAMMRewAADBcT7CcsLi5WfX29bDabNm3apJkz\nZ/rPamtrtXv3bkVHRysjI0Nr166VJG3fvl2ffPKJenp69Morr2jx4sXBHhsAgLAV1NhfvHhR169f\nV0VFha5du6ZNmzapoqLCf75161YdPnxYycnJysvL0/PPPy+v16srV66ooqJCra2tevHFF4k9AADP\nIKixd7vdWrRokSRp6tSpunv3rnw+n8aOHaumpiYlJCRowoQJkqTMzEy53W6tWrXK/+4/Pj5e9+/f\n14MHDxQdHR3M0QEACFtB/cze6/UqMTHRf9vhcMjj8UiSPB6PHA7HY2fR0dGKi4uTJJ04cUIZGRmE\nHgCAZxD0z+z/P8uy+n3fDz/8UCdOnNCRI0f6df/ExDjFxETeDwVJSfZQjxD22GHg2GHg2GHg2OHn\nghp7p9Mpr9frv93S0qKkpKQnnt2+fVtOp1OSdP78eR04cEBvv/227Pb+/cdrbe0cxMnDQ1KSXR7P\nvVCPEdbYYeDYYeDYYeAicYd9/XAT1Mv46enpOnPmjCSpsbFRTqdTY8eOlSRNmjRJPp9Pzc3N6unp\nUU1NjdLT03Xv3j1t375dBw8e1Lhx44I5LgAARgjqO/vU1FTNmDFDOTk5stlsKiwsVHV1tex2u7Ky\nsrR582bl5+dLkpYsWaIpU6b4/xT+unXr/N+npKREEydODOboAACELZv1LB+ch5FIu3wjReZlq8HG\nDgPHDgPHDgMXiTscNpfxAQBA8BF7AAAMR+wBADAcsQcAwHDEHgAAwxF7AAAMR+wBADAcsQcAwHDE\nHgAAwxF7AAAMR+wBADAcsQcAwHDEHgAAwxF7AAAMR+wBADAcsQcAwHDEHgAAwxF7AAAMR+wBADAc\nsQcAwHDEHgAAwxF7AAAMR+wBADAcsQcAwHDEHgAAwxF7AAAMR+wBADAcsQcAwHDEHgAAwxF7AAAM\nR+wBADAcsQcAwHDEHgAAwxF7AAAMR+wBADAcsQcAwHDEHgAAwxF7AAAMR+wBADAcsQcAwHDEHgAA\nwxF7AAAM98yx7+rq0n/+85+hmAUAAAyBmP7c6eDBg4qLi9OKFSu0fPlyjRkzRunp6Vq3bt1QzwcA\nAALUr3f2NTU1ysvL0+nTp/Wtb31LVVVVqqurG+rZAADAIOhX7GNiYmSz2XTu3DktWrRIkvTw4cMh\nHQwAAAyOfl3Gt9vtWrNmjW7duqU5c+aopqZGNpttQE9YXFys+vp62Ww2bdq0STNnzvSf1dbWavfu\n3YqOjlZGRobWrl371McAAIC+9Sv2u3btUm1trVJTUyVJI0eOVElJyTM/2cWLF3X9+nVVVFTo2rVr\n2rRpkyoqKvznW7du1eHDh5WcnKy8vDw9//zzunPnTp+PAQAAfevXZfw7d+4oMTFRDodDlZWVOnXq\nlO7fv//MT+Z2u/0fA0ydOlV3796Vz+eTJDU1NSkhIUETJkxQVFSUMjMz5Xa7+3wMAAB4un69s9+4\ncaM2bNigy5cvq6qqSj/+8Y+1detW/e53v3umJ/N6vZoxY4b/tsPhkMfj0dixY+XxeORwOHqdNTU1\nqbW19Qsf05fExDjFxEQ/03wmSEqyh3qEsMcOA8cOA8cOA8cOP9ev2NtsNs2cOVN79uzRSy+9pMzM\nzGcO/ZNYljVkj2lt7Xzm7x3ukpLs8njuhXqMsMYOA8cOA8cOAxeJO+zrh5t+Xcbv7OxUQ0ODzpw5\no4yMDHV1dam9vf2ZB3E6nfJ6vf7bLS0tSkpKeuLZ7du35XQ6+3wMAAB4un7F/oc//KHeeOMNZWdn\ny+FwaO/evVq6dOkzP1l6errOnDkjSWpsbJTT6fRfjp80aZJ8Pp+am5vV09Ojmpoapaen9/kYAADw\ndDbrGa6lt7W1yWazKT4+fsB/9W7nzp36+OOPZbPZVFhYqMuXL8tutysrK0v/+Mc/tHPnTknS4sWL\ntXr16ic+Zvr06U99nki7fCNF5mWrwcYOA8cOA8cOAxeJO+zrMn6/Yv/JJ5/o9ddfV0dHhx4+fKjE\nxETt2LFDKSkpgzroYIq0/8hSZP7PPdjYYeDYYeDYYeAicYd9xb5ff0Bv9+7d2r9/v6ZNmyZJunz5\nsoqKilReXj44EwIAgCHTr8/so6Ki/KGXpG984xuKjo68v9YGAEA46nfsz5w5I5/PJ5/Ppz/96U/E\nHgCAMNGvy/i//OUvtWXLFr3xxhuy2WyaNWuWfvWrXw31bAAAYBD0GftVq1b5/9S9ZVn62te+Jkny\n+XwqKCjgM3sAAMJAn7Fft25dsOYAAABDpM/Yz5s3L1hzAACAIdKvP6AHAADCF7EHAMBwxB4AAMMR\newAADEfsAQAwHLEHAMBwxB4AAMMRewAADEfsAQAwHLEHAMBwxB4AAMMRewAADEfsAQAwHLEHAMBw\nxB4AAMMRewAADEfsAQAwHLEHAMBwxB4AAMMRewAADEfsAQAwHLEHAMBwxB4AAMMRewAADEfsAQAw\nHLEHAMBwxB4AAMMRewAADEfsAQAwHLEHAMBwxB4AAMMRewAADEfsAQAwHLEHAMBwxB4AAMMRewAA\nDEfsAQAwHLEHAMBwMcF8su7ubhUUFOjmzZuKjo7Wr3/9a02ePLnXfU6ePKmysjJFRUVp5cqVcrlc\n6unp0c9+9jPduHFDDx480E9/+lPNnTs3mKMDABC2gvrO/tSpU4qPj9exY8f06quvateuXb3OOzs7\nVVpaqnfeeUdHjx5VWVmZ2tra9Mc//lGjR4/WsWPHVFRUpG3btgVzbAAAwlpQY+92u5WVlSVJWrBg\ngerq6nqd19fXKyUlRXa7XaNGjVJqaqrq6ur0wgsvaOPGjZIkh8Ohtra2YI4NAEBYC+plfK/XK4fD\nIUmKioqSzWZTV1eXYmNjHzuXHoXd4/FoxIgR/q+VlZVp6dKlwRwbAICwNmSxr6qqUlVVVa+v1dfX\n97ptWVaf3+N/z8vLy9XY2KgDBw489fkTE+MUExPdz2nNkZRkD/UIYY8dBo4dBo4dBo4dfm7IYu9y\nueRyuXp9raCgQB6PR9OnT1d3d7csy/K/q5ckp9Mpr9frv93S0qLZs2dLevTDw0cffaT9+/f3eqf/\nRVpbOwfplYSPpCS7PJ57oR4jrLHDwLHDwLHDwEXiDvv64Saon9mnp6fr9OnTkqSamhrNnz+/1/ms\nWbN06dIltbe3q6OjQ3V1dZo7d66ampp0/Phx7du3TyNHjgzmyAAAhL2gfma/ZMkS1dbWKjc3V7Gx\nsf4/VX/o0CGlpaVpzpw5ys/P1+rVq2Wz2bR27VrZ7Xa99dZbamtr05o1a/zf6/Dhw72uCgAAgCez\nWU/74DxMRdrlGykyL1sNNnYYOHYYOHYYuEjc4bC5jA8AAIKP2AMAYDhiDwCA4Yg9AACGI/YAABiO\n2AMAYDhiDwCA4Yg9AACGI/YAABiO2AMAYDhiDwCA4Yg9AACGI/YAABiO2AMAYDhiDwCA4Yg9AACG\nI/YAABiO2AMAYDhiDwCA4Yg9AACGI/YAABiO2AMAYDhiDwCA4Yg9AACGI/YAABiO2AMAYDhiDwCA\n4Yg9AACGI/YAABiO2AMAYDhiDwCA4Yg9AACGI/YAABiO2AMAYDhiDwCA4Yg9AACGI/YAABiO2AMA\nYDhiDwCA4Yg9AACGI/YAABiO2AMAYDhiDwCA4Yg9AACGI/YAABguqLHv7u5Wfn6+cnNzlZeXp6am\npsfuc/LkSS1fvlwul0tVVVW9zrxer9LS0nThwoVgjQwAQNgLauxPnTql+Ph4HTt2TK+++qp27drV\n67yzs1OlpaV65513dPToUZWVlamtrc1/vn37dk2ePDmYIwMAEPaCGnu3262srCxJ0oIFC1RXV9fr\nvL6+XikpKbLb7Ro1apRSU1P993G73RozZoymTZsWzJEBAAh7QY291+uVw+F49MRRUbLZbOrq6nri\nuSQ5HA55PB51dXWptLRU69evD+a4AAAYIWaovnFVVdVjn7nX19f3um1ZVp/f47PzQ4cOyeVyKT4+\nvt/Pn5gYp5iY6H7f3xRJSfZQjxD22GHg2GHg2GHg2OHnhiz2LpdLLper19cKCgrk8Xg0ffp0dXd3\ny7IsxcbG+s+dTqe8Xq//dktLi2bPnq333ntPDx8+VHl5uW7cuKGGhgbt2bNHzz333Bc+f2tr5+C/\nqGEuKckuj+deqMcIa+wwcOwwcOwwcJG4w75+uAnqZfz09HSdPn1aklRTU6P58+f3Op81a5YuXbqk\n9vZ2dXR0qK6uTnPnztXx48dVWVmpyspKLVy4UIWFhX2GHgAAfG7I3tk/yZIlS1RbW6vc3FzFxsZq\n27Ztkh5dpk9LS9OcOXOUn5+v1atXy2azae3atbLbuQwDAEAgbNbTPjgPU5F2+UaKzMtWg40dBo4d\nBo4dBi4SdzhsLuMDAIDgI/YAABiO2AMAYDhiDwCA4Yg9AACGI/YAABiO2AMAYDhiDwCA4Yg9AACG\nI/YAABiO2AMAYDhiDwCA4Yg9AACGI/YAABiO2AMAYDhiDwCA4Yg9AACGI/YAABiO2AMAYDhiDwCA\n4Yg9AACGI/YAABiO2AMAYDhiDwCA4Yg9AACGI/YAABiO2AMAYDhiDwCA4Yg9AACGI/YAABiO2AMA\nYDhiDwCA4Yg9AACGI/YAABiO2AMAYDhiDwCA4WyWZVmhHgIAAAwd3tkDAGA4Yg8AgOGIPQAAhiP2\nAAAYjtgDAGA4Yg8AgOGIfRjp7u5Wfn6+cnNzlZeXp6ampsfuc/LkSS1fvlwul0tVVVW9zrxer9LS\n0nThwoVgjTzsDHSHPT09ev3115Wbm6uVK1fq448/Dvbow0JxcbGys7OVk5OjhoaGXme1tbVasWKF\nsrOzVVpa2q/HRKqB7HH79u3Kzs7W8uXL9cEHHwR75GFnIDuUpE8//VSLFi1SdXV1MMcNPQtho7q6\n2tq8ebNlWZZ1/vx56yc/+Umv846ODmvx4sVWe3u7df/+feu73/2u1dra6j/fsGGD9eKLL1p///vf\ngzr3cDLQHZ44ccIqLCy0LMuy/vWvf1nLly8P9ughd+HCBWvNmjWWZVnW1atXrZUrV/Y6/853vmPd\nvHnTevDggZWbm2tduXLlqY+JRAPZo9vttl5++WXLsizrzp07VmZmZrDHHlYGssPP7N6921q2bJn1\n7rvvBnXmUOOdfRhxu93KysqSJC1YsEB1dXW9zuvr65WSkiK73a5Ro0YpNTXVfx+3260xY8Zo2rRp\nQZ97OBnoDl944QVt3LhRkuRwONTW1hb02UPN7XZr0aJFkqSpU6fq7t278vl8kqSmpiYlJCRowoQJ\nioqKUmZmptxud5+PiVQD2WNaWpr27NkjSYqPj9f9+/f14MGDkL2GUBvIDiXp2rVrunr1qhYuXBiq\n0UOG2IcRr9crh8MhSYqKipLNZlNXV9cTz6VHUfJ4POrq6lJpaanWr18f9JmHm4HucMSIERo5cqQk\nqaysTEuXLg3u4MOA1+tVYmKi//Znu5Ekj8fzxL319ZhINZA9RkdHKy4uTpJ04sQJZWRkKDo6OriD\nDyMD2aEklZSUqKCgILjDDhMxoR4AT1ZVVfXYZ+719fW9bltP+U3Hn50fOnRILpdL8fHxgzvkMDeY\nO/xMeXm5GhsbdeDAgcEZMow9bXeD9RjTPctOPvzwQ504cUJHjhwZwonCT392+P7772v27NmaPHly\nECYafoj9MOVyueRyuXp9raCgQB6PR9OnT1d3d7csy1JsbKz/3Ol0yuv1+m+3tLRo9uzZeu+99/Tw\n4UOVl5frxo0bamho0J49e/Tcc88F7fWEwmDuUHr0w8NHH32k/fv3a8SIEcF5EcPIk3aTlJT0xLPb\nt2/L6XRqxIgRX/iYSDWQPUrS+fPndeDAAb399tuy2+3BHXqYGcgOz549q6amJp09e1a3bt1SbGys\nxo8frwULFgR9/lDgMn4YSU9P1+nTpyVJNTU1mj9/fq/zWbNm6dKlS2pvb1dHR4fq6uo0d+5cHT9+\nXJWVlaqsrNTChQtVWFhofOi/yEB32NTUpOPHj2vfvn3+y/mRJj09XWfOnJEkNTY2yul0auzYsZKk\nSZMmyefzqbm5WT09PaqpqVF6enqfj4lUA9njvXv3tH37dh08eFDjxo0L5fjDwkB2+Oabb+rdd99V\nZWWlXC6XfvSjH0VM6CXe2YeVJUuWqLa2Vrm5uYqNjdW2bdskPbpMn5aWpjlz5ig/P1+rV6+WzWbT\n2rVrI/4dwP8a6A7feusttbW1ac2aNf7vdfjw4V5XBUyXmpqqGTNmKCcnRzabTYWFhaqurpbdbldW\nVpY2b96s/Px8SY/2PGXKFE2ZMuWxx0S6geyxoqJCra2tWrdunf/7lJSUaOLEiaF6GSE1kB1GOv6J\nWwAADMdlfAAADEfsAQAwHLEHAMBwxB4AAMMRewAADEfsAQRVdXW1XnvttVCPAUQUYg8AgOH4pToA\nnujo0aP685//rAcPHuirX/2qXn75Zb3yyivKyMjQP//5T0nSb37zGyUnJ+vs2bMqLS3VqFGjNHr0\naG3ZskXJycmqr69XcXGxRowYoYSEBJWUlEiSfD6fXnvtNV27dk0TJ07Uvn37ZLPZQvlyAaPxzh7A\nYxoaGvSXv/xF5eXlqqiokN1uV21trZqamrRs2TL94Q9/0Lx583TkyBHdv39fP//5z7V3714dPXpU\nGRkZevPNNyVJGzZs0JYtW/T73/9eaWlp+utf/ypJunr1qrZs2aLq6mpduXJFjY2NoXy5gPF4Zw/g\nMRcuXNCNGzf0/e9/X5LU2dmp27dva9y4cfrmN78p6dGvLC0rK9O///1vfelLX9L48eMlSfPmzdPx\n48d1584dtbe3a9q0aZKkH/zgB5IefWafkpKi0aNHS5KSk5N17969IL9CILIQewCPiY2N1be//W39\n4he/8H+tublZy5Yt89+2LEs2m+2xy+///+tf9Nu4//ffYue3dgNDi8v4AB6Tmpqqc+fOqaOjQ5JU\nXl4uj8eju3fv6vLly5Kkuro6ff3rX9dXvvIV/fe//9XNmzclSW63W7NmzVJiYqLGjRunhoYGSdKR\nI0dUXl4emhcERDje2QN4TEpKil566SV973vf08iRI+V0OjV//nwlJyerurpa27Ztk2VZ2r17t0aN\nGqWioiKtX79esbGxiouLU1FRkSRpx44dKi4uVkxMjOx2u3bs2KEPPvggxK8OiDz8q3cA+qW5uVmr\nVq3SuXPnQj0KgGfEZXwAAAzHO3sAAAzHO3sAAAxH7AEAMByxBwDAcMQeAADDEXsAAAxH7AEAMNz/\nARYWsboLg8ctAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "SoaN6tQdoJLs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(accuracies,'C0',label='Trainset accuracies')\n",
        "plt.plot(validation_accuracies,'C1',label='Validation accuracies')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cX5AxMa-5Yyn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Save/load model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "a5u7oAE8nLL7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ipNnYH8aAIIW",
        "colab_type": "code",
        "outputId": "0a4831a9-aaae-4673-a2e5-0c2db8d339db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"model_at_epoch_0pt\"))\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (bnorm128): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bnorm32): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (b1d): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc1): Linear(in_features=1792, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "metadata": {
        "id": "W0Fo8dfggtGM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Exporting solution to csv"
      ]
    },
    {
      "metadata": {
        "id": "MNhP3CRzT_r-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "downloaded = drive.CreateFile({'id': '1GBix_QORVrfRmbg9mLmwWnBQgMxHQV2Z'})\n",
        "downloaded.GetContentFile('test_images.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dNYU4jNyUBco",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!unzip test_images.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "--9uoIcLD1br",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "25YtJPPx0nHc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#len(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Zh0oxbAqHPj_",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def answer_builder(model):\n",
        "  \"\"\"\n",
        "  Performs inference on testset and exports predictions to answer.csv\n",
        "  \"\"\"\n",
        "  model.eval()\n",
        "  test = pd.read_csv('test.csv')\n",
        "  test_names = test['image_name']\n",
        "  images =torch.empty([55,3,224,224])\n",
        "  with torch.no_grad():\n",
        "    for itr in tqdm(range(0,int(len(test_names)/55))):\n",
        "      for idx in (range(55*itr,55*(itr+1))):\n",
        "        img_name = os.path.join(\"/content/test_images/\", test_names[idx])\n",
        "        image = Image.open(img_name)\n",
        "        image = tfms(image)\n",
        "        image = image.unsqueeze(0)\n",
        "        images[idx-55*itr,:,:,:] = image\n",
        "   # print('\\nPerforming inference...')\n",
        "      images = images.cuda()\n",
        "      target = model(images) #55x4\n",
        "      target = torch.stack((target[:,0]*640,target[:,1]*640,target[:,2]*480,target[:,3]*480),1)\n",
        "      target = torch.round(target)\n",
        "   # print('Generating answer.csv')\n",
        "      for i in range(0,55):\n",
        "        test.loc[55*itr+i] = [test_names[55*itr+i]] +  target[i].tolist()\n",
        "\n",
        "    test.to_csv('answer.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o2WDFjrdHRpm",
        "colab_type": "code",
        "outputId": "ff10206b-344d-410a-978c-658e9e0ba6b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4012
        }
      },
      "cell_type": "code",
      "source": [
        "answer_builder(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/233 [00:00<?, ?it/s]\u001b[A\n",
            "  0%|          | 1/233 [00:01<04:58,  1.29s/it]\u001b[A\n",
            "  1%|          | 2/233 [00:02<04:55,  1.28s/it]\u001b[A\n",
            "  1%|▏         | 3/233 [00:03<04:52,  1.27s/it]\u001b[A\n",
            "  2%|▏         | 4/233 [00:05<04:49,  1.26s/it]\u001b[A\n",
            "  2%|▏         | 5/233 [00:06<04:46,  1.26s/it]\u001b[A\n",
            "  3%|▎         | 6/233 [00:07<04:44,  1.25s/it]\u001b[A\n",
            "  3%|▎         | 7/233 [00:08<04:43,  1.25s/it]\u001b[A\n",
            "  3%|▎         | 8/233 [00:10<04:39,  1.24s/it]\u001b[A\n",
            "  4%|▍         | 9/233 [00:11<04:37,  1.24s/it]\u001b[A\n",
            "  4%|▍         | 10/233 [00:12<04:38,  1.25s/it]\u001b[A\n",
            "  5%|▍         | 11/233 [00:13<04:35,  1.24s/it]\u001b[A\n",
            "  5%|▌         | 12/233 [00:14<04:32,  1.23s/it]\u001b[A\n",
            "  6%|▌         | 13/233 [00:16<04:31,  1.23s/it]\u001b[A\n",
            "  6%|▌         | 14/233 [00:17<04:30,  1.24s/it]\u001b[A\n",
            "  6%|▋         | 15/233 [00:18<04:29,  1.24s/it]\u001b[A\n",
            "  7%|▋         | 16/233 [00:19<04:28,  1.24s/it]\u001b[A\n",
            "  7%|▋         | 17/233 [00:21<04:26,  1.23s/it]\u001b[A\n",
            "  8%|▊         | 18/233 [00:22<04:24,  1.23s/it]\u001b[A\n",
            "  8%|▊         | 19/233 [00:23<04:23,  1.23s/it]\u001b[A\n",
            "  9%|▊         | 20/233 [00:24<04:21,  1.23s/it]\u001b[A\n",
            "  9%|▉         | 21/233 [00:26<04:19,  1.23s/it]\u001b[A\n",
            "  9%|▉         | 22/233 [00:27<04:22,  1.24s/it]\u001b[A\n",
            " 10%|▉         | 23/233 [00:28<04:22,  1.25s/it]\u001b[A\n",
            " 10%|█         | 24/233 [00:29<04:21,  1.25s/it]\u001b[A\n",
            " 11%|█         | 25/233 [00:31<04:22,  1.26s/it]\u001b[A\n",
            " 11%|█         | 26/233 [00:32<04:22,  1.27s/it]\u001b[A\n",
            " 12%|█▏        | 27/233 [00:33<04:20,  1.27s/it]\u001b[A\n",
            " 12%|█▏        | 28/233 [00:34<04:20,  1.27s/it]\u001b[A\n",
            " 12%|█▏        | 29/233 [00:36<04:19,  1.27s/it]\u001b[A\n",
            " 13%|█▎        | 30/233 [00:37<04:19,  1.28s/it]\u001b[A\n",
            " 13%|█▎        | 31/233 [00:38<04:16,  1.27s/it]\u001b[A\n",
            " 14%|█▎        | 32/233 [00:40<04:14,  1.27s/it]\u001b[A\n",
            " 14%|█▍        | 33/233 [00:41<04:12,  1.26s/it]\u001b[A\n",
            " 15%|█▍        | 34/233 [00:42<04:13,  1.28s/it]\u001b[A\n",
            " 15%|█▌        | 35/233 [00:43<04:13,  1.28s/it]\u001b[A\n",
            " 15%|█▌        | 36/233 [00:45<04:11,  1.28s/it]\u001b[A\n",
            " 16%|█▌        | 37/233 [00:46<04:09,  1.27s/it]\u001b[A\n",
            " 16%|█▋        | 38/233 [00:47<04:08,  1.28s/it]\u001b[A\n",
            " 17%|█▋        | 39/233 [00:48<04:07,  1.27s/it]\u001b[A\n",
            " 17%|█▋        | 40/233 [00:50<04:06,  1.28s/it]\u001b[A\n",
            " 18%|█▊        | 41/233 [00:51<04:03,  1.27s/it]\u001b[A\n",
            " 18%|█▊        | 42/233 [00:52<04:01,  1.27s/it]\u001b[A\n",
            " 18%|█▊        | 43/233 [00:54<04:02,  1.28s/it]\u001b[A\n",
            " 19%|█▉        | 44/233 [00:55<03:59,  1.27s/it]\u001b[A\n",
            " 19%|█▉        | 45/233 [00:56<03:57,  1.26s/it]\u001b[A\n",
            " 20%|█▉        | 46/233 [00:57<03:55,  1.26s/it]\u001b[A\n",
            " 20%|██        | 47/233 [00:59<03:54,  1.26s/it]\u001b[A\n",
            " 21%|██        | 48/233 [01:00<03:53,  1.26s/it]\u001b[A\n",
            " 21%|██        | 49/233 [01:01<03:50,  1.25s/it]\u001b[A\n",
            " 21%|██▏       | 50/233 [01:02<03:51,  1.27s/it]\u001b[A\n",
            " 22%|██▏       | 51/233 [01:04<03:50,  1.27s/it]\u001b[A\n",
            " 22%|██▏       | 52/233 [01:05<03:49,  1.27s/it]\u001b[A\n",
            " 23%|██▎       | 53/233 [01:06<03:47,  1.26s/it]\u001b[A\n",
            " 23%|██▎       | 54/233 [01:07<03:46,  1.26s/it]\u001b[A\n",
            " 24%|██▎       | 55/233 [01:09<03:44,  1.26s/it]\u001b[A\n",
            " 24%|██▍       | 56/233 [01:10<03:43,  1.26s/it]\u001b[A\n",
            " 24%|██▍       | 57/233 [01:11<03:40,  1.25s/it]\u001b[A\n",
            " 25%|██▍       | 58/233 [01:12<03:40,  1.26s/it]\u001b[A\n",
            " 25%|██▌       | 59/233 [01:14<03:39,  1.26s/it]\u001b[A\n",
            " 26%|██▌       | 60/233 [01:15<03:38,  1.26s/it]\u001b[A\n",
            " 26%|██▌       | 61/233 [01:16<03:37,  1.27s/it]\u001b[A\n",
            " 27%|██▋       | 62/233 [01:18<03:37,  1.27s/it]\u001b[A\n",
            " 27%|██▋       | 63/233 [01:19<03:35,  1.27s/it]\u001b[A\n",
            " 27%|██▋       | 64/233 [01:20<03:33,  1.26s/it]\u001b[A\n",
            " 28%|██▊       | 65/233 [01:21<03:32,  1.27s/it]\u001b[A\n",
            " 28%|██▊       | 66/233 [01:23<03:32,  1.27s/it]\u001b[A\n",
            " 29%|██▉       | 67/233 [01:24<03:31,  1.28s/it]\u001b[A\n",
            " 29%|██▉       | 68/233 [01:25<03:29,  1.27s/it]\u001b[A\n",
            " 30%|██▉       | 69/233 [01:26<03:27,  1.27s/it]\u001b[A\n",
            " 30%|███       | 70/233 [01:28<03:26,  1.26s/it]\u001b[A\n",
            " 30%|███       | 71/233 [01:29<03:25,  1.27s/it]\u001b[A\n",
            " 31%|███       | 72/233 [01:30<03:23,  1.26s/it]\u001b[A\n",
            " 31%|███▏      | 73/233 [01:31<03:21,  1.26s/it]\u001b[A\n",
            " 32%|███▏      | 74/233 [01:33<03:21,  1.27s/it]\u001b[A\n",
            " 32%|███▏      | 75/233 [01:34<03:20,  1.27s/it]\u001b[A\n",
            " 33%|███▎      | 76/233 [01:35<03:18,  1.27s/it]\u001b[A\n",
            " 33%|███▎      | 77/233 [01:37<03:16,  1.26s/it]\u001b[A\n",
            " 33%|███▎      | 78/233 [01:38<03:16,  1.27s/it]\u001b[A\n",
            " 34%|███▍      | 79/233 [01:39<03:13,  1.26s/it]\u001b[A\n",
            " 34%|███▍      | 80/233 [01:40<03:11,  1.25s/it]\u001b[A\n",
            " 35%|███▍      | 81/233 [01:42<03:10,  1.25s/it]\u001b[A\n",
            " 35%|███▌      | 82/233 [01:43<03:09,  1.26s/it]\u001b[A\n",
            " 36%|███▌      | 83/233 [01:44<03:09,  1.26s/it]\u001b[A\n",
            " 36%|███▌      | 84/233 [01:45<03:06,  1.25s/it]\u001b[A\n",
            " 36%|███▋      | 85/233 [01:47<03:03,  1.24s/it]\u001b[A\n",
            " 37%|███▋      | 86/233 [01:48<03:03,  1.25s/it]\u001b[A\n",
            " 37%|███▋      | 87/233 [01:49<03:04,  1.27s/it]\u001b[A\n",
            " 38%|███▊      | 88/233 [01:50<03:04,  1.27s/it]\u001b[A\n",
            " 38%|███▊      | 89/233 [01:52<03:02,  1.26s/it]\u001b[A\n",
            " 39%|███▊      | 90/233 [01:53<03:02,  1.27s/it]\u001b[A\n",
            " 39%|███▉      | 91/233 [01:54<03:00,  1.27s/it]\u001b[A\n",
            " 39%|███▉      | 92/233 [01:55<02:58,  1.26s/it]\u001b[A\n",
            " 40%|███▉      | 93/233 [01:57<02:56,  1.26s/it]\u001b[A\n",
            " 40%|████      | 94/233 [01:58<02:54,  1.26s/it]\u001b[A\n",
            " 41%|████      | 95/233 [01:59<02:53,  1.26s/it]\u001b[A\n",
            " 41%|████      | 96/233 [02:00<02:52,  1.26s/it]\u001b[A\n",
            " 42%|████▏     | 97/233 [02:02<02:51,  1.26s/it]\u001b[A\n",
            " 42%|████▏     | 98/233 [02:03<02:50,  1.26s/it]\u001b[A\n",
            " 42%|████▏     | 99/233 [02:04<02:48,  1.26s/it]\u001b[A\n",
            " 43%|████▎     | 100/233 [02:05<02:47,  1.26s/it]\u001b[A\n",
            " 43%|████▎     | 101/233 [02:07<02:45,  1.26s/it]\u001b[A\n",
            " 44%|████▍     | 102/233 [02:08<02:45,  1.26s/it]\u001b[A\n",
            " 44%|████▍     | 103/233 [02:09<02:44,  1.26s/it]\u001b[A\n",
            " 45%|████▍     | 104/233 [02:11<02:41,  1.25s/it]\u001b[A\n",
            " 45%|████▌     | 105/233 [02:12<02:39,  1.25s/it]\u001b[A\n",
            " 45%|████▌     | 106/233 [02:13<02:38,  1.24s/it]\u001b[A\n",
            " 46%|████▌     | 107/233 [02:14<02:37,  1.25s/it]\u001b[A\n",
            " 46%|████▋     | 108/233 [02:15<02:35,  1.25s/it]\u001b[A\n",
            " 47%|████▋     | 109/233 [02:17<02:35,  1.25s/it]\u001b[A\n",
            " 47%|████▋     | 110/233 [02:18<02:34,  1.25s/it]\u001b[A\n",
            " 48%|████▊     | 111/233 [02:19<02:33,  1.26s/it]\u001b[A\n",
            " 48%|████▊     | 112/233 [02:20<02:29,  1.24s/it]\u001b[A\n",
            " 48%|████▊     | 113/233 [02:22<02:27,  1.23s/it]\u001b[A\n",
            " 49%|████▉     | 114/233 [02:23<02:27,  1.24s/it]\u001b[A\n",
            " 49%|████▉     | 115/233 [02:24<02:26,  1.24s/it]\u001b[A\n",
            " 50%|████▉     | 116/233 [02:25<02:25,  1.24s/it]\u001b[A\n",
            " 50%|█████     | 117/233 [02:27<02:24,  1.24s/it]\u001b[A\n",
            " 51%|█████     | 118/233 [02:28<02:23,  1.25s/it]\u001b[A\n",
            " 51%|█████     | 119/233 [02:29<02:23,  1.26s/it]\u001b[A\n",
            " 52%|█████▏    | 120/233 [02:30<02:22,  1.26s/it]\u001b[A\n",
            " 52%|█████▏    | 121/233 [02:32<02:20,  1.25s/it]\u001b[A\n",
            " 52%|█████▏    | 122/233 [02:33<02:19,  1.26s/it]\u001b[A\n",
            " 53%|█████▎    | 123/233 [02:34<02:18,  1.26s/it]\u001b[A\n",
            " 53%|█████▎    | 124/233 [02:35<02:16,  1.26s/it]\u001b[A\n",
            " 54%|█████▎    | 125/233 [02:37<02:15,  1.25s/it]\u001b[A\n",
            " 54%|█████▍    | 126/233 [02:38<02:15,  1.26s/it]\u001b[A\n",
            " 55%|█████▍    | 127/233 [02:39<02:13,  1.26s/it]\u001b[A\n",
            " 55%|█████▍    | 128/233 [02:41<02:12,  1.26s/it]\u001b[A\n",
            " 55%|█████▌    | 129/233 [02:42<02:10,  1.26s/it]\u001b[A\n",
            " 56%|█████▌    | 130/233 [02:43<02:10,  1.27s/it]\u001b[A\n",
            " 56%|█████▌    | 131/233 [02:44<02:10,  1.28s/it]\u001b[A\n",
            " 57%|█████▋    | 132/233 [02:46<02:08,  1.27s/it]\u001b[A\n",
            " 57%|█████▋    | 133/233 [02:47<02:06,  1.26s/it]\u001b[A\n",
            " 58%|█████▊    | 134/233 [02:48<02:04,  1.26s/it]\u001b[A\n",
            " 58%|█████▊    | 135/233 [02:49<02:03,  1.26s/it]\u001b[A\n",
            " 58%|█████▊    | 136/233 [02:51<02:01,  1.25s/it]\u001b[A\n",
            " 59%|█████▉    | 137/233 [02:52<02:00,  1.25s/it]\u001b[A\n",
            " 59%|█████▉    | 138/233 [02:53<02:00,  1.27s/it]\u001b[A\n",
            " 60%|█████▉    | 139/233 [02:54<01:59,  1.27s/it]\u001b[A\n",
            " 60%|██████    | 140/233 [02:56<01:56,  1.26s/it]\u001b[A\n",
            " 61%|██████    | 141/233 [02:57<01:55,  1.26s/it]\u001b[A\n",
            " 61%|██████    | 142/233 [02:58<01:54,  1.26s/it]\u001b[A\n",
            " 61%|██████▏   | 143/233 [02:59<01:53,  1.26s/it]\u001b[A\n",
            " 62%|██████▏   | 144/233 [03:01<01:52,  1.26s/it]\u001b[A\n",
            " 62%|██████▏   | 145/233 [03:02<01:51,  1.26s/it]\u001b[A\n",
            " 63%|██████▎   | 146/233 [03:03<01:49,  1.26s/it]\u001b[A\n",
            " 63%|██████▎   | 147/233 [03:04<01:48,  1.26s/it]\u001b[A\n",
            " 64%|██████▎   | 148/233 [03:06<01:46,  1.25s/it]\u001b[A\n",
            " 64%|██████▍   | 149/233 [03:07<01:45,  1.26s/it]\u001b[A\n",
            " 64%|██████▍   | 150/233 [03:08<01:44,  1.26s/it]\u001b[A\n",
            " 65%|██████▍   | 151/233 [03:10<01:44,  1.27s/it]\u001b[A\n",
            " 65%|██████▌   | 152/233 [03:11<01:42,  1.27s/it]\u001b[A\n",
            " 66%|██████▌   | 153/233 [03:12<01:41,  1.27s/it]\u001b[A\n",
            " 66%|██████▌   | 154/233 [03:13<01:40,  1.27s/it]\u001b[A\n",
            " 67%|██████▋   | 155/233 [03:15<01:39,  1.28s/it]\u001b[A\n",
            " 67%|██████▋   | 156/233 [03:16<01:37,  1.27s/it]\u001b[A\n",
            " 67%|██████▋   | 157/233 [03:17<01:36,  1.27s/it]\u001b[A\n",
            " 68%|██████▊   | 158/233 [03:18<01:35,  1.27s/it]\u001b[A\n",
            " 68%|██████▊   | 159/233 [03:20<01:34,  1.27s/it]\u001b[A\n",
            " 69%|██████▊   | 160/233 [03:21<01:32,  1.27s/it]\u001b[A\n",
            " 69%|██████▉   | 161/233 [03:22<01:30,  1.26s/it]\u001b[A\n",
            " 70%|██████▉   | 162/233 [03:23<01:29,  1.26s/it]\u001b[A\n",
            " 70%|██████▉   | 163/233 [03:25<01:28,  1.26s/it]\u001b[A\n",
            " 70%|███████   | 164/233 [03:26<01:25,  1.24s/it]\u001b[A\n",
            " 71%|███████   | 165/233 [03:27<01:24,  1.25s/it]\u001b[A\n",
            " 71%|███████   | 166/233 [03:29<01:24,  1.26s/it]\u001b[A\n",
            " 72%|███████▏  | 167/233 [03:30<01:23,  1.26s/it]\u001b[A\n",
            " 72%|███████▏  | 168/233 [03:31<01:21,  1.25s/it]\u001b[A\n",
            " 73%|███████▎  | 169/233 [03:32<01:19,  1.25s/it]\u001b[A\n",
            " 73%|███████▎  | 170/233 [03:34<01:19,  1.26s/it]\u001b[A\n",
            " 73%|███████▎  | 171/233 [03:35<01:18,  1.27s/it]\u001b[A\n",
            " 74%|███████▍  | 172/233 [03:36<01:17,  1.26s/it]\u001b[A\n",
            " 74%|███████▍  | 173/233 [03:37<01:15,  1.26s/it]\u001b[A\n",
            " 75%|███████▍  | 174/233 [03:39<01:13,  1.25s/it]\u001b[A\n",
            " 75%|███████▌  | 175/233 [03:40<01:12,  1.26s/it]\u001b[A\n",
            " 76%|███████▌  | 176/233 [03:41<01:11,  1.26s/it]\u001b[A\n",
            " 76%|███████▌  | 177/233 [03:42<01:09,  1.25s/it]\u001b[A\n",
            " 76%|███████▋  | 178/233 [03:44<01:08,  1.25s/it]\u001b[A\n",
            " 77%|███████▋  | 179/233 [03:45<01:07,  1.25s/it]\u001b[A\n",
            " 77%|███████▋  | 180/233 [03:46<01:06,  1.25s/it]\u001b[A\n",
            " 78%|███████▊  | 181/233 [03:47<01:04,  1.24s/it]\u001b[A\n",
            " 78%|███████▊  | 182/233 [03:49<01:03,  1.24s/it]\u001b[A\n",
            " 79%|███████▊  | 183/233 [03:50<01:02,  1.24s/it]\u001b[A\n",
            " 79%|███████▉  | 184/233 [03:51<01:01,  1.25s/it]\u001b[A\n",
            " 79%|███████▉  | 185/233 [03:52<01:00,  1.26s/it]\u001b[A\n",
            " 80%|███████▉  | 186/233 [03:54<00:59,  1.27s/it]\u001b[A\n",
            " 80%|████████  | 187/233 [03:55<00:58,  1.26s/it]\u001b[A\n",
            " 81%|████████  | 188/233 [03:56<00:56,  1.26s/it]\u001b[A\n",
            " 81%|████████  | 189/233 [03:57<00:55,  1.26s/it]\u001b[A\n",
            " 82%|████████▏ | 190/233 [03:59<00:54,  1.27s/it]\u001b[A\n",
            " 82%|████████▏ | 191/233 [04:00<00:53,  1.27s/it]\u001b[A\n",
            " 82%|████████▏ | 192/233 [04:01<00:52,  1.27s/it]\u001b[A\n",
            " 83%|████████▎ | 193/233 [04:02<00:50,  1.27s/it]\u001b[A\n",
            " 83%|████████▎ | 194/233 [04:04<00:49,  1.28s/it]\u001b[A\n",
            " 84%|████████▎ | 195/233 [04:05<00:48,  1.27s/it]\u001b[A\n",
            " 84%|████████▍ | 196/233 [04:06<00:46,  1.27s/it]\u001b[A\n",
            " 85%|████████▍ | 197/233 [04:08<00:45,  1.27s/it]\u001b[A\n",
            " 85%|████████▍ | 198/233 [04:09<00:44,  1.28s/it]\u001b[A\n",
            " 85%|████████▌ | 199/233 [04:10<00:43,  1.27s/it]\u001b[A\n",
            " 86%|████████▌ | 200/233 [04:11<00:41,  1.27s/it]\u001b[A\n",
            " 86%|████████▋ | 201/233 [04:13<00:40,  1.27s/it]\u001b[A\n",
            " 87%|████████▋ | 202/233 [04:14<00:39,  1.27s/it]\u001b[A\n",
            " 87%|████████▋ | 203/233 [04:15<00:38,  1.28s/it]\u001b[A\n",
            " 88%|████████▊ | 204/233 [04:16<00:36,  1.26s/it]\u001b[A\n",
            " 88%|████████▊ | 205/233 [04:18<00:35,  1.26s/it]\u001b[A\n",
            " 88%|████████▊ | 206/233 [04:19<00:34,  1.26s/it]\u001b[A\n",
            " 89%|████████▉ | 207/233 [04:20<00:32,  1.27s/it]\u001b[A\n",
            " 89%|████████▉ | 208/233 [04:21<00:31,  1.26s/it]\u001b[A\n",
            " 90%|████████▉ | 209/233 [04:23<00:30,  1.27s/it]\u001b[A\n",
            " 90%|█████████ | 210/233 [04:24<00:29,  1.27s/it]\u001b[A\n",
            " 91%|█████████ | 211/233 [04:25<00:28,  1.27s/it]\u001b[A\n",
            " 91%|█████████ | 212/233 [04:27<00:26,  1.26s/it]\u001b[A\n",
            " 91%|█████████▏| 213/233 [04:28<00:24,  1.25s/it]\u001b[A\n",
            " 92%|█████████▏| 214/233 [04:29<00:23,  1.25s/it]\u001b[A\n",
            " 92%|█████████▏| 215/233 [04:30<00:22,  1.25s/it]\u001b[A\n",
            " 93%|█████████▎| 216/233 [04:32<00:21,  1.25s/it]\u001b[A\n",
            " 93%|█████████▎| 217/233 [04:33<00:19,  1.24s/it]\u001b[A\n",
            " 94%|█████████▎| 218/233 [04:34<00:18,  1.25s/it]\u001b[A\n",
            " 94%|█████████▍| 219/233 [04:35<00:17,  1.26s/it]\u001b[A\n",
            " 94%|█████████▍| 220/233 [04:37<00:16,  1.25s/it]\u001b[A\n",
            " 95%|█████████▍| 221/233 [04:38<00:15,  1.25s/it]\u001b[A\n",
            " 95%|█████████▌| 222/233 [04:39<00:13,  1.26s/it]\u001b[A\n",
            " 96%|█████████▌| 223/233 [04:40<00:12,  1.27s/it]\u001b[A\n",
            " 96%|█████████▌| 224/233 [04:42<00:11,  1.26s/it]\u001b[A\n",
            " 97%|█████████▋| 225/233 [04:43<00:10,  1.27s/it]\u001b[A\n",
            " 97%|█████████▋| 226/233 [04:44<00:08,  1.27s/it]\u001b[A\n",
            " 97%|█████████▋| 227/233 [04:45<00:07,  1.26s/it]\u001b[A\n",
            " 98%|█████████▊| 228/233 [04:47<00:06,  1.25s/it]\u001b[A\n",
            " 98%|█████████▊| 229/233 [04:48<00:04,  1.24s/it]\u001b[A\n",
            " 99%|█████████▊| 230/233 [04:49<00:03,  1.25s/it]\u001b[A\n",
            " 99%|█████████▉| 231/233 [04:50<00:02,  1.24s/it]\u001b[A\n",
            "100%|█████████▉| 232/233 [04:52<00:01,  1.24s/it]\u001b[A\n",
            "100%|██████████| 233/233 [04:53<00:00,  1.24s/it]\u001b[A\n",
            "\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q-xwHkVDxID6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ans = pd.read_csv('answer.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OhV1gxeqxLo4",
        "colab_type": "code",
        "outputId": "717b2382-d9ce-4930-f792-86dc7a1c3902",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1969
        }
      },
      "cell_type": "code",
      "source": [
        "ans"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>y1</th>\n",
              "      <th>y2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1474723840903DSC08089.png</td>\n",
              "      <td>246.0</td>\n",
              "      <td>481.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>425.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1473231475010DeeplearnS11276.png</td>\n",
              "      <td>112.0</td>\n",
              "      <td>536.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>374.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>JPEG_20161205_135307_1000155917326.png</td>\n",
              "      <td>174.0</td>\n",
              "      <td>528.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>471.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>JPEG_20160711_123440_1000518778437.png</td>\n",
              "      <td>243.0</td>\n",
              "      <td>410.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>390.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>JPEG_20160803_115329_100034020722.png</td>\n",
              "      <td>85.0</td>\n",
              "      <td>489.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>414.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>147444974116511473239803010-Mast--Harbour-Men-...</td>\n",
              "      <td>86.0</td>\n",
              "      <td>445.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>404.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>JPEG_20160622_110649_1000527459853.png</td>\n",
              "      <td>98.0</td>\n",
              "      <td>454.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>366.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>JPEG_20160823_120737_1000784898268.png</td>\n",
              "      <td>70.0</td>\n",
              "      <td>469.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>399.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1480965956645IMG_3094.png</td>\n",
              "      <td>174.0</td>\n",
              "      <td>550.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>409.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>14732348976417a565e40d545452688130062b267a2d2.png</td>\n",
              "      <td>71.0</td>\n",
              "      <td>580.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>416.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1474723374370DSC07852.png</td>\n",
              "      <td>225.0</td>\n",
              "      <td>431.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>478.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>JPEG_20160820_111118_100011668802.png</td>\n",
              "      <td>216.0</td>\n",
              "      <td>406.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>433.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>JPEG_20160706_105226_100087855419.png</td>\n",
              "      <td>75.0</td>\n",
              "      <td>531.0</td>\n",
              "      <td>221.0</td>\n",
              "      <td>354.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>JPEG_20160621_155839_100073846506.png</td>\n",
              "      <td>266.0</td>\n",
              "      <td>480.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>402.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1480940089861_R2A1904.png</td>\n",
              "      <td>125.0</td>\n",
              "      <td>546.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>480.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1474637513144DSC06780.png</td>\n",
              "      <td>173.0</td>\n",
              "      <td>361.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>437.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>JPEG_20161123_170015_1000183903221.png</td>\n",
              "      <td>163.0</td>\n",
              "      <td>399.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>406.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>JPEG_20161205_152655_1000319785884.png</td>\n",
              "      <td>118.0</td>\n",
              "      <td>459.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>398.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>14806550588121473324459p2-500x500.png</td>\n",
              "      <td>120.0</td>\n",
              "      <td>560.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>380.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>JPEG_20160913_110021_1000554801748.png</td>\n",
              "      <td>69.0</td>\n",
              "      <td>544.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>331.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>JPEG_20161028_113656_1000884495593.png</td>\n",
              "      <td>51.0</td>\n",
              "      <td>585.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>437.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1480485006674IMG_20161129_181135.png</td>\n",
              "      <td>59.0</td>\n",
              "      <td>640.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>475.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1468666217374JPEG_20160712_164026_100095190148...</td>\n",
              "      <td>43.0</td>\n",
              "      <td>488.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>351.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1475159286472DSC08150.png</td>\n",
              "      <td>220.0</td>\n",
              "      <td>403.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>397.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1473662770499DeeplearnS11593.png</td>\n",
              "      <td>57.0</td>\n",
              "      <td>602.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>420.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>JPEG_20161121_172423_1000451802749.png</td>\n",
              "      <td>60.0</td>\n",
              "      <td>548.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>379.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>JPEG_20160711_112635_1000386061474.png</td>\n",
              "      <td>116.0</td>\n",
              "      <td>601.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>347.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>JPEG_20161125_170806_1000294132098.png</td>\n",
              "      <td>162.0</td>\n",
              "      <td>530.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>480.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>1473664771684DeeplearnS11641.png</td>\n",
              "      <td>83.0</td>\n",
              "      <td>409.0</td>\n",
              "      <td>155.0</td>\n",
              "      <td>292.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>JPEG_20161125_142000_1000881308475.png</td>\n",
              "      <td>175.0</td>\n",
              "      <td>454.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>443.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12785</th>\n",
              "      <td>JPEG_20160527_155707_1000436681221.png</td>\n",
              "      <td>34.0</td>\n",
              "      <td>556.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>431.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12786</th>\n",
              "      <td>1472036697076pyellow1.png</td>\n",
              "      <td>25.0</td>\n",
              "      <td>542.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>389.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12787</th>\n",
              "      <td>1473315151219DeeplearnS11541.png</td>\n",
              "      <td>121.0</td>\n",
              "      <td>611.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>401.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12788</th>\n",
              "      <td>JPEG_20161114_164147_1000717591566.png</td>\n",
              "      <td>157.0</td>\n",
              "      <td>437.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>402.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12789</th>\n",
              "      <td>JPEG_20160810_125457_1000618891946.png</td>\n",
              "      <td>148.0</td>\n",
              "      <td>586.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>436.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12790</th>\n",
              "      <td>1473662761056DeeplearnS11590.png</td>\n",
              "      <td>87.0</td>\n",
              "      <td>545.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>339.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12791</th>\n",
              "      <td>1474724287220DSC08133.png</td>\n",
              "      <td>112.0</td>\n",
              "      <td>587.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>415.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12792</th>\n",
              "      <td>JPEG_20160924_140500_1000708658172.png</td>\n",
              "      <td>54.0</td>\n",
              "      <td>470.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>348.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12793</th>\n",
              "      <td>JPEG_20160920_160831_1000416032132.png</td>\n",
              "      <td>109.0</td>\n",
              "      <td>512.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>450.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12794</th>\n",
              "      <td>1475158952049DSC06915.png</td>\n",
              "      <td>253.0</td>\n",
              "      <td>392.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>471.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12795</th>\n",
              "      <td>JPEG_20161130_182058_1000451372797.png</td>\n",
              "      <td>38.0</td>\n",
              "      <td>640.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>365.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12796</th>\n",
              "      <td>JPEG_20160625_140951_1000716933208.png</td>\n",
              "      <td>111.0</td>\n",
              "      <td>502.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>333.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12797</th>\n",
              "      <td>147772335227620161028_162146.png</td>\n",
              "      <td>44.0</td>\n",
              "      <td>498.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>350.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12798</th>\n",
              "      <td>JPEG_20160704_123939_1000567540935.png</td>\n",
              "      <td>58.0</td>\n",
              "      <td>508.0</td>\n",
              "      <td>163.0</td>\n",
              "      <td>257.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12799</th>\n",
              "      <td>JPEG_20161123_190951_1000625148732.png</td>\n",
              "      <td>183.0</td>\n",
              "      <td>437.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>429.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12800</th>\n",
              "      <td>JPEG_20160629_101156_1000325247520.png</td>\n",
              "      <td>256.0</td>\n",
              "      <td>432.0</td>\n",
              "      <td>123.0</td>\n",
              "      <td>394.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12801</th>\n",
              "      <td>1480066922928IMG_0070.png</td>\n",
              "      <td>83.0</td>\n",
              "      <td>529.0</td>\n",
              "      <td>149.0</td>\n",
              "      <td>373.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12802</th>\n",
              "      <td>1466828838707IMG_0012.png</td>\n",
              "      <td>53.0</td>\n",
              "      <td>523.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>362.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12803</th>\n",
              "      <td>1473661129579DeeplearnS11485.png</td>\n",
              "      <td>135.0</td>\n",
              "      <td>604.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>398.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12804</th>\n",
              "      <td>JPEG_20161126_174407_1000803975586.png</td>\n",
              "      <td>147.0</td>\n",
              "      <td>621.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>270.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12805</th>\n",
              "      <td>JPEG_20161125_154250_1000612628801.png</td>\n",
              "      <td>170.0</td>\n",
              "      <td>422.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>313.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12806</th>\n",
              "      <td>JPEG_20160607_135204_1000721004919.png</td>\n",
              "      <td>140.0</td>\n",
              "      <td>473.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>375.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12807</th>\n",
              "      <td>1468495348616DSC_0193.png</td>\n",
              "      <td>82.0</td>\n",
              "      <td>451.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>417.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12808</th>\n",
              "      <td>JPEG_20161126_141844_1000772813429.png</td>\n",
              "      <td>100.0</td>\n",
              "      <td>598.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>439.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12809</th>\n",
              "      <td>1473751292174IMG_0982.png</td>\n",
              "      <td>74.0</td>\n",
              "      <td>640.0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>450.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12810</th>\n",
              "      <td>JPEG_20161104_103201_1000965398606.png</td>\n",
              "      <td>59.0</td>\n",
              "      <td>542.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>461.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12811</th>\n",
              "      <td>JPEG_20160711_114732_1000663038627.png</td>\n",
              "      <td>241.0</td>\n",
              "      <td>405.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>422.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12812</th>\n",
              "      <td>JPEG_20160621_104610_1000370989775.png</td>\n",
              "      <td>132.0</td>\n",
              "      <td>451.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>392.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12813</th>\n",
              "      <td>JPEG_20160621_111238_1000136858311.png</td>\n",
              "      <td>131.0</td>\n",
              "      <td>516.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>313.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12814</th>\n",
              "      <td>1473751123070IMG_0992.png</td>\n",
              "      <td>88.0</td>\n",
              "      <td>587.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>401.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12815 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              image_name     x1     x2     y1  \\\n",
              "0                              1474723840903DSC08089.png  246.0  481.0   59.0   \n",
              "1                       1473231475010DeeplearnS11276.png  112.0  536.0  142.0   \n",
              "2                 JPEG_20161205_135307_1000155917326.png  174.0  528.0   40.0   \n",
              "3                 JPEG_20160711_123440_1000518778437.png  243.0  410.0   84.0   \n",
              "4                  JPEG_20160803_115329_100034020722.png   85.0  489.0   68.0   \n",
              "5      147444974116511473239803010-Mast--Harbour-Men-...   86.0  445.0   85.0   \n",
              "6                 JPEG_20160622_110649_1000527459853.png   98.0  454.0  111.0   \n",
              "7                 JPEG_20160823_120737_1000784898268.png   70.0  469.0   80.0   \n",
              "8                              1480965956645IMG_3094.png  174.0  550.0  100.0   \n",
              "9      14732348976417a565e40d545452688130062b267a2d2.png   71.0  580.0   55.0   \n",
              "10                             1474723374370DSC07852.png  225.0  431.0   17.0   \n",
              "11                 JPEG_20160820_111118_100011668802.png  216.0  406.0   31.0   \n",
              "12                 JPEG_20160706_105226_100087855419.png   75.0  531.0  221.0   \n",
              "13                 JPEG_20160621_155839_100073846506.png  266.0  480.0   61.0   \n",
              "14                             1480940089861_R2A1904.png  125.0  546.0   89.0   \n",
              "15                             1474637513144DSC06780.png  173.0  361.0   45.0   \n",
              "16                JPEG_20161123_170015_1000183903221.png  163.0  399.0   44.0   \n",
              "17                JPEG_20161205_152655_1000319785884.png  118.0  459.0   52.0   \n",
              "18                 14806550588121473324459p2-500x500.png  120.0  560.0   34.0   \n",
              "19                JPEG_20160913_110021_1000554801748.png   69.0  544.0  106.0   \n",
              "20                JPEG_20161028_113656_1000884495593.png   51.0  585.0   94.0   \n",
              "21                  1480485006674IMG_20161129_181135.png   59.0  640.0   87.0   \n",
              "22     1468666217374JPEG_20160712_164026_100095190148...   43.0  488.0   93.0   \n",
              "23                             1475159286472DSC08150.png  220.0  403.0   78.0   \n",
              "24                      1473662770499DeeplearnS11593.png   57.0  602.0   97.0   \n",
              "25                JPEG_20161121_172423_1000451802749.png   60.0  548.0   71.0   \n",
              "26                JPEG_20160711_112635_1000386061474.png  116.0  601.0  219.0   \n",
              "27                JPEG_20161125_170806_1000294132098.png  162.0  530.0  102.0   \n",
              "28                      1473664771684DeeplearnS11641.png   83.0  409.0  155.0   \n",
              "29                JPEG_20161125_142000_1000881308475.png  175.0  454.0   17.0   \n",
              "...                                                  ...    ...    ...    ...   \n",
              "12785             JPEG_20160527_155707_1000436681221.png   34.0  556.0  100.0   \n",
              "12786                          1472036697076pyellow1.png   25.0  542.0   46.0   \n",
              "12787                   1473315151219DeeplearnS11541.png  121.0  611.0   96.0   \n",
              "12788             JPEG_20161114_164147_1000717591566.png  157.0  437.0   67.0   \n",
              "12789             JPEG_20160810_125457_1000618891946.png  148.0  586.0   30.0   \n",
              "12790                   1473662761056DeeplearnS11590.png   87.0  545.0  100.0   \n",
              "12791                          1474724287220DSC08133.png  112.0  587.0   51.0   \n",
              "12792             JPEG_20160924_140500_1000708658172.png   54.0  470.0   93.0   \n",
              "12793             JPEG_20160920_160831_1000416032132.png  109.0  512.0   27.0   \n",
              "12794                          1475158952049DSC06915.png  253.0  392.0   38.0   \n",
              "12795             JPEG_20161130_182058_1000451372797.png   38.0  640.0   97.0   \n",
              "12796             JPEG_20160625_140951_1000716933208.png  111.0  502.0   95.0   \n",
              "12797                   147772335227620161028_162146.png   44.0  498.0   45.0   \n",
              "12798             JPEG_20160704_123939_1000567540935.png   58.0  508.0  163.0   \n",
              "12799             JPEG_20161123_190951_1000625148732.png  183.0  437.0   41.0   \n",
              "12800             JPEG_20160629_101156_1000325247520.png  256.0  432.0  123.0   \n",
              "12801                          1480066922928IMG_0070.png   83.0  529.0  149.0   \n",
              "12802                          1466828838707IMG_0012.png   53.0  523.0   31.0   \n",
              "12803                   1473661129579DeeplearnS11485.png  135.0  604.0  102.0   \n",
              "12804             JPEG_20161126_174407_1000803975586.png  147.0  621.0  174.0   \n",
              "12805             JPEG_20161125_154250_1000612628801.png  170.0  422.0   66.0   \n",
              "12806             JPEG_20160607_135204_1000721004919.png  140.0  473.0   54.0   \n",
              "12807                          1468495348616DSC_0193.png   82.0  451.0   50.0   \n",
              "12808             JPEG_20161126_141844_1000772813429.png  100.0  598.0  136.0   \n",
              "12809                          1473751292174IMG_0982.png   74.0  640.0  157.0   \n",
              "12810             JPEG_20161104_103201_1000965398606.png   59.0  542.0   59.0   \n",
              "12811             JPEG_20160711_114732_1000663038627.png  241.0  405.0   44.0   \n",
              "12812             JPEG_20160621_104610_1000370989775.png  132.0  451.0   39.0   \n",
              "12813             JPEG_20160621_111238_1000136858311.png  131.0  516.0  112.0   \n",
              "12814                          1473751123070IMG_0992.png   88.0  587.0   61.0   \n",
              "\n",
              "          y2  \n",
              "0      425.0  \n",
              "1      374.0  \n",
              "2      471.0  \n",
              "3      390.0  \n",
              "4      414.0  \n",
              "5      404.0  \n",
              "6      366.0  \n",
              "7      399.0  \n",
              "8      409.0  \n",
              "9      416.0  \n",
              "10     478.0  \n",
              "11     433.0  \n",
              "12     354.0  \n",
              "13     402.0  \n",
              "14     480.0  \n",
              "15     437.0  \n",
              "16     406.0  \n",
              "17     398.0  \n",
              "18     380.0  \n",
              "19     331.0  \n",
              "20     437.0  \n",
              "21     475.0  \n",
              "22     351.0  \n",
              "23     397.0  \n",
              "24     420.0  \n",
              "25     379.0  \n",
              "26     347.0  \n",
              "27     480.0  \n",
              "28     292.0  \n",
              "29     443.0  \n",
              "...      ...  \n",
              "12785  431.0  \n",
              "12786  389.0  \n",
              "12787  401.0  \n",
              "12788  402.0  \n",
              "12789  436.0  \n",
              "12790  339.0  \n",
              "12791  415.0  \n",
              "12792  348.0  \n",
              "12793  450.0  \n",
              "12794  471.0  \n",
              "12795  365.0  \n",
              "12796  333.0  \n",
              "12797  350.0  \n",
              "12798  257.0  \n",
              "12799  429.0  \n",
              "12800  394.0  \n",
              "12801  373.0  \n",
              "12802  362.0  \n",
              "12803  398.0  \n",
              "12804  270.0  \n",
              "12805  313.0  \n",
              "12806  375.0  \n",
              "12807  417.0  \n",
              "12808  439.0  \n",
              "12809  450.0  \n",
              "12810  461.0  \n",
              "12811  422.0  \n",
              "12812  392.0  \n",
              "12813  313.0  \n",
              "12814  401.0  \n",
              "\n",
              "[12815 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "metadata": {
        "id": "V9A28TDT5hB0",
        "colab_type": "code",
        "outputId": "87d4e5a9-0f56-4830-cfc4-b376404bab61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8469
        }
      },
      "cell_type": "code",
      "source": [
        "ans = pd.read_csv('answer.csv')\n",
        "for i in tqdm(range(len(ans))):\n",
        "  if(ans['x1'][i]<0):\n",
        "    ans['x1'][i]=0\n",
        "  elif(ans['x1'][i]>640):\n",
        "    ans['x1'][i]=640\n",
        "    \n",
        "  if(ans['x2'][i]<0):\n",
        "    ans['x2'][i]=0\n",
        "  elif(ans['x2'][i]>640):\n",
        "    ans['x2'][i]=640\n",
        "    \n",
        "  if(ans['y1'][i]<0):\n",
        "    ans['y1'][i]=0\n",
        "  elif(ans['y1'][i]>480):\n",
        "    ans['y1'][i]=480\n",
        "    \n",
        "  if(ans['y2'][i]<0):\n",
        "    ans['y2'][i]=0\n",
        "  elif(ans['y2'][i]>480):\n",
        "    ans['y2'][i]=480"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/12815 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "\n",
            "  0%|          | 6/12815 [00:00<04:40, 45.72it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  after removing the cwd from sys.path.\n",
            "\n",
            "  0%|          | 23/12815 [00:00<03:42, 57.53it/s]\u001b[A\n",
            "  0%|          | 35/12815 [00:00<03:14, 65.57it/s]\u001b[A\n",
            "  0%|          | 51/12815 [00:00<02:42, 78.46it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \n",
            "\n",
            "  1%|          | 79/12815 [00:00<02:09, 98.46it/s]\u001b[A\n",
            "  1%|          | 154/12815 [00:00<01:36, 131.56it/s]\u001b[A\n",
            "  1%|▏         | 182/12815 [00:00<01:22, 152.42it/s]\u001b[A\n",
            "  2%|▏         | 231/12815 [00:00<01:06, 188.20it/s]\u001b[A\n",
            "  2%|▏         | 263/12815 [00:01<01:06, 189.37it/s]\u001b[A\n",
            "  2%|▏         | 291/12815 [00:01<01:02, 199.28it/s]\u001b[A\n",
            "  3%|▎         | 353/12815 [00:01<00:51, 241.45it/s]\u001b[A\n",
            "  3%|▎         | 386/12815 [00:01<01:39, 125.11it/s]\u001b[A\n",
            "  3%|▎         | 411/12815 [00:02<01:39, 125.04it/s]\u001b[A\n",
            "  3%|▎         | 434/12815 [00:02<01:36, 127.90it/s]\u001b[A\n",
            "  4%|▎         | 464/12815 [00:02<01:22, 149.22it/s]\u001b[A\n",
            "  4%|▍         | 485/12815 [00:02<01:25, 144.42it/s]\u001b[A\n",
            "  4%|▍         | 504/12815 [00:02<01:21, 151.95it/s]\u001b[A\n",
            "  4%|▍         | 523/12815 [00:02<01:19, 155.40it/s]\u001b[A\n",
            "  4%|▍         | 555/12815 [00:02<01:07, 181.53it/s]\u001b[A\n",
            "  5%|▍         | 577/12815 [00:03<01:04, 188.41it/s]\u001b[A\n",
            "  5%|▍         | 599/12815 [00:03<01:11, 170.97it/s]\u001b[A\n",
            "  5%|▍         | 618/12815 [00:03<01:13, 165.17it/s]\u001b[A\n",
            "  5%|▌         | 663/12815 [00:03<01:01, 198.96it/s]\u001b[A\n",
            "  5%|▌         | 687/12815 [00:03<01:06, 181.02it/s]\u001b[A\n",
            "  6%|▌         | 709/12815 [00:03<01:22, 147.45it/s]\u001b[A\n",
            "  6%|▌         | 727/12815 [00:03<01:19, 151.44it/s]\u001b[A\n",
            "  6%|▌         | 745/12815 [00:04<01:37, 123.86it/s]\u001b[A\n",
            "  6%|▌         | 773/12815 [00:04<01:23, 144.98it/s]\u001b[A\n",
            "  7%|▋         | 840/12815 [00:04<01:07, 178.15it/s]\u001b[A\n",
            "  7%|▋         | 864/12815 [00:04<01:09, 170.94it/s]\u001b[A\n",
            "  7%|▋         | 886/12815 [00:04<01:07, 177.53it/s]\u001b[A\n",
            "  7%|▋         | 907/12815 [00:04<01:32, 128.21it/s]\u001b[A\n",
            "  7%|▋         | 924/12815 [00:05<01:28, 135.06it/s]\u001b[A\n",
            "  8%|▊         | 968/12815 [00:05<01:10, 167.05it/s]\u001b[A\n",
            "  8%|▊         | 1004/12815 [00:05<01:01, 190.87it/s]\u001b[A\n",
            "  8%|▊         | 1029/12815 [00:05<01:05, 178.69it/s]\u001b[A\n",
            "  8%|▊         | 1051/12815 [00:05<01:04, 182.87it/s]\u001b[A\n",
            "  9%|▊         | 1106/12815 [00:05<00:52, 224.55it/s]\u001b[A\n",
            "  9%|▉         | 1136/12815 [00:06<01:18, 148.71it/s]\u001b[A\n",
            "  9%|▉         | 1159/12815 [00:06<01:25, 135.84it/s]\u001b[A\n",
            "  9%|▉         | 1179/12815 [00:06<01:23, 139.43it/s]\u001b[A\n",
            "  9%|▉         | 1198/12815 [00:06<01:35, 122.14it/s]\u001b[A\n",
            "  9%|▉         | 1214/12815 [00:06<01:52, 102.81it/s]\u001b[A\n",
            " 10%|▉         | 1270/12815 [00:06<01:25, 134.47it/s]\u001b[A\n",
            " 10%|█         | 1312/12815 [00:07<01:09, 165.49it/s]\u001b[A\n",
            " 10%|█         | 1340/12815 [00:07<01:18, 145.91it/s]\u001b[A\n",
            " 11%|█         | 1363/12815 [00:07<01:13, 155.18it/s]\u001b[A\n",
            " 11%|█         | 1385/12815 [00:07<01:08, 165.99it/s]\u001b[A\n",
            " 11%|█         | 1406/12815 [00:07<01:05, 174.58it/s]\u001b[A\n",
            " 11%|█         | 1440/12815 [00:07<00:57, 199.41it/s]\u001b[A\n",
            " 11%|█▏        | 1464/12815 [00:07<01:04, 175.08it/s]\u001b[A\n",
            " 12%|█▏        | 1485/12815 [00:08<01:02, 180.11it/s]\u001b[A\n",
            " 12%|█▏        | 1513/12815 [00:08<00:57, 197.77it/s]\u001b[A\n",
            " 12%|█▏        | 1535/12815 [00:08<01:04, 175.95it/s]\u001b[A\n",
            " 12%|█▏        | 1555/12815 [00:08<01:14, 150.30it/s]\u001b[A\n",
            " 12%|█▏        | 1580/12815 [00:08<01:07, 167.55it/s]\u001b[A\n",
            " 13%|█▎        | 1605/12815 [00:08<01:02, 180.80it/s]\u001b[A\n",
            " 13%|█▎        | 1625/12815 [00:08<01:12, 155.08it/s]\u001b[A\n",
            " 13%|█▎        | 1649/12815 [00:08<01:06, 168.62it/s]\u001b[A\n",
            " 13%|█▎        | 1668/12815 [00:09<01:06, 168.53it/s]\u001b[A\n",
            " 13%|█▎        | 1686/12815 [00:09<01:07, 165.88it/s]\u001b[A\n",
            " 14%|█▎        | 1759/12815 [00:09<00:52, 210.78it/s]\u001b[A\n",
            " 14%|█▍        | 1789/12815 [00:09<01:07, 164.06it/s]\u001b[A\n",
            " 14%|█▍        | 1813/12815 [00:09<01:02, 176.86it/s]\u001b[A\n",
            " 14%|█▍        | 1837/12815 [00:09<01:06, 164.86it/s]\u001b[A\n",
            " 15%|█▍        | 1869/12815 [00:10<01:03, 173.49it/s]\u001b[A\n",
            " 15%|█▍        | 1890/12815 [00:10<01:01, 178.41it/s]\u001b[A\n",
            " 15%|█▌        | 1937/12815 [00:10<00:50, 215.24it/s]\u001b[A\n",
            " 15%|█▌        | 1964/12815 [00:10<00:49, 217.39it/s]\u001b[A\n",
            " 16%|█▌        | 1990/12815 [00:10<01:02, 172.83it/s]\u001b[A\n",
            " 16%|█▌        | 2012/12815 [00:10<01:15, 143.13it/s]\u001b[A\n",
            " 16%|█▌        | 2030/12815 [00:10<01:21, 131.60it/s]\u001b[A\n",
            " 16%|█▌        | 2068/12815 [00:11<01:07, 160.20it/s]\u001b[A\n",
            " 16%|█▋        | 2089/12815 [00:11<01:10, 151.99it/s]\u001b[A\n",
            " 16%|█▋        | 2112/12815 [00:11<01:06, 161.80it/s]\u001b[A\n",
            " 17%|█▋        | 2131/12815 [00:11<01:23, 127.87it/s]\u001b[A\n",
            " 17%|█▋        | 2149/12815 [00:11<01:19, 134.45it/s]\u001b[A\n",
            " 17%|█▋        | 2165/12815 [00:11<01:19, 134.26it/s]\u001b[A\n",
            " 17%|█▋        | 2180/12815 [00:11<01:20, 132.84it/s]\u001b[A\n",
            " 17%|█▋        | 2202/12815 [00:12<01:11, 148.66it/s]\u001b[A\n",
            " 17%|█▋        | 2224/12815 [00:12<01:05, 160.60it/s]\u001b[A\n",
            " 17%|█▋        | 2242/12815 [00:12<01:30, 116.53it/s]\u001b[A\n",
            " 18%|█▊        | 2259/12815 [00:12<01:25, 123.02it/s]\u001b[A\n",
            " 18%|█▊        | 2274/12815 [00:12<01:23, 125.99it/s]\u001b[A\n",
            " 18%|█▊        | 2292/12815 [00:12<01:18, 133.57it/s]\u001b[A\n",
            " 18%|█▊        | 2314/12815 [00:12<01:11, 146.58it/s]\u001b[A\n",
            " 18%|█▊        | 2330/12815 [00:13<01:12, 144.07it/s]\u001b[A\n",
            " 18%|█▊        | 2348/12815 [00:13<01:10, 148.66it/s]\u001b[A\n",
            " 18%|█▊        | 2364/12815 [00:13<01:09, 149.59it/s]\u001b[A\n",
            " 19%|█▊        | 2385/12815 [00:13<01:13, 142.59it/s]\u001b[A\n",
            " 19%|█▉        | 2403/12815 [00:13<01:09, 149.00it/s]\u001b[A\n",
            " 19%|█▉        | 2433/12815 [00:13<01:01, 167.68it/s]\u001b[A\n",
            " 19%|█▉        | 2451/12815 [00:13<01:19, 130.31it/s]\u001b[A\n",
            " 19%|█▉        | 2467/12815 [00:13<01:16, 134.47it/s]\u001b[A\n",
            " 19%|█▉        | 2488/12815 [00:14<01:09, 148.21it/s]\u001b[A\n",
            " 20%|█▉        | 2557/12815 [00:14<00:53, 190.29it/s]\u001b[A\n",
            " 20%|██        | 2586/12815 [00:14<01:31, 111.59it/s]\u001b[A\n",
            " 20%|██        | 2608/12815 [00:14<01:33, 109.52it/s]\u001b[A\n",
            " 21%|██        | 2632/12815 [00:15<01:19, 127.99it/s]\u001b[A\n",
            " 21%|██        | 2653/12815 [00:15<01:12, 140.73it/s]\u001b[A\n",
            " 21%|██        | 2672/12815 [00:15<01:15, 133.80it/s]\u001b[A\n",
            " 21%|██        | 2702/12815 [00:15<01:09, 145.04it/s]\u001b[A\n",
            " 21%|██        | 2720/12815 [00:15<01:17, 130.07it/s]\u001b[A\n",
            " 21%|██▏       | 2736/12815 [00:15<01:15, 134.18it/s]\u001b[A\n",
            " 21%|██▏       | 2751/12815 [00:15<01:25, 118.18it/s]\u001b[A\n",
            " 22%|██▏       | 2780/12815 [00:16<01:11, 141.28it/s]\u001b[A\n",
            " 22%|██▏       | 2798/12815 [00:16<01:16, 131.04it/s]\u001b[A\n",
            " 22%|██▏       | 2814/12815 [00:16<01:32, 107.73it/s]\u001b[A\n",
            " 22%|██▏       | 2857/12815 [00:16<01:12, 136.93it/s]\u001b[A\n",
            " 22%|██▏       | 2878/12815 [00:16<01:07, 146.34it/s]\u001b[A\n",
            " 23%|██▎       | 2898/12815 [00:16<01:06, 148.76it/s]\u001b[A\n",
            " 23%|██▎       | 2917/12815 [00:16<01:04, 153.78it/s]\u001b[A\n",
            " 23%|██▎       | 2935/12815 [00:17<01:10, 139.93it/s]\u001b[A\n",
            " 23%|██▎       | 2953/12815 [00:17<01:07, 145.22it/s]\u001b[A\n",
            " 23%|██▎       | 2969/12815 [00:17<01:07, 145.26it/s]\u001b[A\n",
            " 23%|██▎       | 2985/12815 [00:17<01:16, 128.22it/s]\u001b[A\n",
            " 24%|██▎       | 3030/12815 [00:17<01:01, 160.34it/s]\u001b[A\n",
            " 24%|██▍       | 3052/12815 [00:17<00:57, 169.42it/s]\u001b[A\n",
            " 24%|██▍       | 3083/12815 [00:17<00:52, 186.63it/s]\u001b[A\n",
            " 24%|██▍       | 3131/12815 [00:17<00:43, 223.13it/s]\u001b[A\n",
            " 25%|██▍       | 3159/12815 [00:18<00:51, 187.20it/s]\u001b[A\n",
            " 25%|██▍       | 3183/12815 [00:18<00:56, 171.47it/s]\u001b[A\n",
            " 25%|██▌       | 3204/12815 [00:18<00:54, 177.59it/s]\u001b[A\n",
            " 25%|██▌       | 3225/12815 [00:18<01:00, 158.95it/s]\u001b[A\n",
            " 25%|██▌       | 3244/12815 [00:18<01:06, 143.25it/s]\u001b[A\n",
            " 25%|██▌       | 3261/12815 [00:18<01:15, 126.71it/s]\u001b[A\n",
            " 26%|██▌       | 3276/12815 [00:18<01:22, 115.85it/s]\u001b[A\n",
            " 26%|██▌       | 3289/12815 [00:19<01:21, 116.73it/s]\u001b[A\n",
            " 26%|██▌       | 3316/12815 [00:19<01:14, 127.79it/s]\u001b[A\n",
            " 26%|██▋       | 3369/12815 [00:19<00:58, 162.68it/s]\u001b[A\n",
            " 26%|██▋       | 3393/12815 [00:19<01:00, 156.65it/s]\u001b[A\n",
            " 27%|██▋       | 3414/12815 [00:19<00:56, 166.49it/s]\u001b[A\n",
            " 27%|██▋       | 3435/12815 [00:19<00:56, 164.82it/s]\u001b[A\n",
            " 27%|██▋       | 3454/12815 [00:19<00:55, 167.80it/s]\u001b[A\n",
            " 27%|██▋       | 3473/12815 [00:20<01:03, 148.14it/s]\u001b[A\n",
            " 27%|██▋       | 3524/12815 [00:20<00:50, 184.02it/s]\u001b[A\n",
            " 28%|██▊       | 3549/12815 [00:20<00:47, 195.82it/s]\u001b[A\n",
            " 28%|██▊       | 3573/12815 [00:20<00:57, 161.12it/s]\u001b[A\n",
            " 28%|██▊       | 3594/12815 [00:20<01:01, 149.61it/s]\u001b[A\n",
            " 28%|██▊       | 3612/12815 [00:20<01:09, 132.27it/s]\u001b[A\n",
            " 28%|██▊       | 3628/12815 [00:20<01:15, 122.06it/s]\u001b[A\n",
            " 28%|██▊       | 3645/12815 [00:21<01:10, 129.45it/s]\u001b[A\n",
            " 29%|██▊       | 3664/12815 [00:21<01:12, 125.95it/s]\u001b[A\n",
            " 29%|██▊       | 3678/12815 [00:21<01:14, 123.25it/s]\u001b[A\n",
            " 29%|██▉       | 3707/12815 [00:21<01:02, 145.14it/s]\u001b[A\n",
            " 29%|██▉       | 3724/12815 [00:21<01:09, 130.52it/s]\u001b[A\n",
            " 29%|██▉       | 3739/12815 [00:21<01:11, 127.20it/s]\u001b[A\n",
            " 30%|██▉       | 3784/12815 [00:21<00:56, 158.70it/s]\u001b[A\n",
            " 30%|██▉       | 3806/12815 [00:22<00:53, 167.30it/s]\u001b[A\n",
            " 30%|██▉       | 3827/12815 [00:22<00:58, 153.76it/s]\u001b[A\n",
            " 31%|███       | 3911/12815 [00:22<00:46, 192.93it/s]\u001b[A\n",
            " 31%|███       | 3952/12815 [00:22<00:39, 223.41it/s]\u001b[A\n",
            " 31%|███       | 3982/12815 [00:22<00:37, 236.76it/s]\u001b[A\n",
            " 31%|███▏      | 4016/12815 [00:22<00:35, 251.20it/s]\u001b[A\n",
            " 32%|███▏      | 4046/12815 [00:23<00:57, 152.47it/s]\u001b[A\n",
            " 32%|███▏      | 4069/12815 [00:23<00:52, 165.77it/s]\u001b[A\n",
            " 32%|███▏      | 4092/12815 [00:23<00:56, 155.55it/s]\u001b[A\n",
            " 32%|███▏      | 4112/12815 [00:23<00:53, 162.55it/s]\u001b[A\n",
            " 32%|███▏      | 4132/12815 [00:23<00:57, 150.43it/s]\u001b[A\n",
            " 32%|███▏      | 4150/12815 [00:23<01:12, 118.95it/s]\u001b[A\n",
            " 33%|███▎      | 4168/12815 [00:23<01:06, 129.70it/s]\u001b[A\n",
            " 33%|███▎      | 4184/12815 [00:24<01:04, 134.86it/s]\u001b[A\n",
            " 33%|███▎      | 4207/12815 [00:24<01:02, 138.04it/s]\u001b[A\n",
            " 33%|███▎      | 4234/12815 [00:24<00:54, 156.83it/s]\u001b[A\n",
            " 33%|███▎      | 4252/12815 [00:24<00:54, 158.15it/s]\u001b[A\n",
            " 33%|███▎      | 4269/12815 [00:24<00:54, 155.93it/s]\u001b[A\n",
            " 34%|███▎      | 4320/12815 [00:24<00:44, 192.38it/s]\u001b[A\n",
            " 34%|███▍      | 4356/12815 [00:24<00:39, 216.38it/s]\u001b[A\n",
            " 35%|███▍      | 4428/12815 [00:24<00:32, 260.76it/s]\u001b[A\n",
            " 35%|███▍      | 4462/12815 [00:25<00:38, 216.83it/s]\u001b[A\n",
            " 35%|███▌      | 4490/12815 [00:25<00:46, 179.92it/s]\u001b[A\n",
            " 35%|███▌      | 4528/12815 [00:25<00:39, 209.74it/s]\u001b[A\n",
            " 36%|███▌      | 4555/12815 [00:25<00:46, 178.99it/s]\u001b[A\n",
            " 36%|███▋      | 4655/12815 [00:25<00:34, 233.50it/s]\u001b[A\n",
            " 37%|███▋      | 4696/12815 [00:25<00:34, 236.36it/s]\u001b[A\n",
            " 37%|███▋      | 4732/12815 [00:26<00:40, 198.74it/s]\u001b[A\n",
            " 37%|███▋      | 4762/12815 [00:26<00:49, 163.96it/s]\u001b[A\n",
            " 37%|███▋      | 4789/12815 [00:26<00:44, 181.75it/s]\u001b[A\n",
            " 38%|███▊      | 4814/12815 [00:26<00:46, 173.11it/s]\u001b[A\n",
            " 38%|███▊      | 4836/12815 [00:26<00:44, 180.71it/s]\u001b[A\n",
            " 38%|███▊      | 4858/12815 [00:27<00:59, 132.88it/s]\u001b[A\n",
            " 38%|███▊      | 4898/12815 [00:27<00:48, 163.08it/s]\u001b[A\n",
            " 38%|███▊      | 4921/12815 [00:27<00:51, 154.02it/s]\u001b[A\n",
            " 39%|███▊      | 4941/12815 [00:27<00:55, 142.72it/s]\u001b[A\n",
            " 39%|███▉      | 4971/12815 [00:27<00:47, 165.50it/s]\u001b[A\n",
            " 39%|███▉      | 5008/12815 [00:27<00:40, 191.87it/s]\u001b[A\n",
            " 39%|███▉      | 5032/12815 [00:27<00:39, 198.65it/s]\u001b[A\n",
            " 39%|███▉      | 5055/12815 [00:28<00:39, 194.42it/s]\u001b[A\n",
            " 40%|███▉      | 5101/12815 [00:28<00:33, 230.36it/s]\u001b[A\n",
            " 40%|████      | 5129/12815 [00:28<00:36, 208.26it/s]\u001b[A\n",
            " 40%|████      | 5154/12815 [00:28<00:50, 153.21it/s]\u001b[A\n",
            " 40%|████      | 5174/12815 [00:28<00:47, 159.68it/s]\u001b[A\n",
            " 41%|████      | 5194/12815 [00:28<00:52, 145.90it/s]\u001b[A\n",
            " 41%|████      | 5223/12815 [00:29<00:50, 151.75it/s]\u001b[A\n",
            " 41%|████      | 5240/12815 [00:29<00:49, 153.17it/s]\u001b[A\n",
            " 41%|████      | 5271/12815 [00:29<00:42, 176.74it/s]\u001b[A\n",
            " 41%|████▏     | 5301/12815 [00:29<00:38, 196.18it/s]\u001b[A\n",
            " 42%|████▏     | 5323/12815 [00:29<00:58, 127.95it/s]\u001b[A\n",
            " 42%|████▏     | 5355/12815 [00:29<00:48, 152.57it/s]\u001b[A\n",
            " 42%|████▏     | 5376/12815 [00:30<01:02, 119.59it/s]\u001b[A\n",
            " 42%|████▏     | 5397/12815 [00:30<00:54, 135.39it/s]\u001b[A\n",
            " 42%|████▏     | 5415/12815 [00:30<00:51, 143.12it/s]\u001b[A\n",
            " 42%|████▏     | 5436/12815 [00:30<00:47, 155.39it/s]\u001b[A\n",
            " 43%|████▎     | 5454/12815 [00:30<00:52, 140.08it/s]\u001b[A\n",
            " 43%|████▎     | 5479/12815 [00:30<00:46, 157.45it/s]\u001b[A\n",
            " 43%|████▎     | 5513/12815 [00:30<00:40, 182.41it/s]\u001b[A\n",
            " 43%|████▎     | 5535/12815 [00:30<00:38, 186.76it/s]\u001b[A\n",
            " 43%|████▎     | 5564/12815 [00:31<00:35, 205.60it/s]\u001b[A\n",
            " 44%|████▎     | 5587/12815 [00:31<00:36, 198.98it/s]\u001b[A\n",
            " 44%|████▍     | 5609/12815 [00:31<00:36, 199.45it/s]\u001b[A\n",
            " 44%|████▍     | 5654/12815 [00:31<00:30, 233.82it/s]\u001b[A\n",
            " 44%|████▍     | 5681/12815 [00:31<00:30, 237.51it/s]\u001b[A\n",
            " 45%|████▍     | 5707/12815 [00:31<00:42, 167.03it/s]\u001b[A\n",
            " 45%|████▍     | 5738/12815 [00:31<00:37, 189.79it/s]\u001b[A\n",
            " 45%|████▌     | 5773/12815 [00:31<00:32, 216.68it/s]\u001b[A\n",
            " 45%|████▌     | 5799/12815 [00:32<00:48, 143.97it/s]\u001b[A\n",
            " 45%|████▌     | 5820/12815 [00:32<00:54, 127.37it/s]\u001b[A\n",
            " 46%|████▌     | 5857/12815 [00:32<00:44, 155.40it/s]\u001b[A\n",
            " 46%|████▌     | 5879/12815 [00:32<00:42, 164.96it/s]\u001b[A\n",
            " 46%|████▌     | 5901/12815 [00:32<00:53, 129.30it/s]\u001b[A\n",
            " 46%|████▌     | 5919/12815 [00:33<00:50, 137.48it/s]\u001b[A\n",
            " 47%|████▋     | 5974/12815 [00:33<00:39, 172.12it/s]\u001b[A\n",
            " 47%|████▋     | 6012/12815 [00:33<00:34, 199.27it/s]\u001b[A\n",
            " 47%|████▋     | 6039/12815 [00:33<00:39, 172.10it/s]\u001b[A\n",
            " 47%|████▋     | 6063/12815 [00:33<00:37, 182.27it/s]\u001b[A\n",
            " 47%|████▋     | 6086/12815 [00:33<00:35, 188.02it/s]\u001b[A\n",
            " 48%|████▊     | 6111/12815 [00:33<00:33, 197.58it/s]\u001b[A\n",
            " 48%|████▊     | 6135/12815 [00:33<00:33, 202.38it/s]\u001b[A\n",
            " 48%|████▊     | 6157/12815 [00:34<00:42, 155.55it/s]\u001b[A\n",
            " 48%|████▊     | 6189/12815 [00:34<00:36, 180.30it/s]\u001b[A\n",
            " 48%|████▊     | 6211/12815 [00:34<00:40, 162.76it/s]\u001b[A\n",
            " 49%|████▊     | 6240/12815 [00:34<00:36, 181.99it/s]\u001b[A\n",
            " 49%|████▉     | 6261/12815 [00:34<00:35, 184.27it/s]\u001b[A\n",
            " 49%|████▉     | 6282/12815 [00:34<00:40, 162.06it/s]\u001b[A\n",
            " 49%|████▉     | 6336/12815 [00:34<00:32, 201.94it/s]\u001b[A\n",
            " 50%|████▉     | 6363/12815 [00:35<00:37, 170.45it/s]\u001b[A\n",
            " 50%|████▉     | 6401/12815 [00:35<00:32, 196.57it/s]\u001b[A\n",
            " 50%|█████     | 6426/12815 [00:35<00:42, 150.14it/s]\u001b[A\n",
            " 50%|█████     | 6447/12815 [00:35<00:40, 158.04it/s]\u001b[A\n",
            " 51%|█████     | 6512/12815 [00:35<00:31, 199.63it/s]\u001b[A\n",
            " 51%|█████     | 6542/12815 [00:36<00:32, 193.91it/s]\u001b[A\n",
            " 51%|█████▏    | 6568/12815 [00:36<00:30, 201.82it/s]\u001b[A\n",
            " 51%|█████▏    | 6593/12815 [00:36<00:30, 203.19it/s]\u001b[A\n",
            " 52%|█████▏    | 6617/12815 [00:36<00:38, 162.44it/s]\u001b[A\n",
            " 52%|█████▏    | 6637/12815 [00:36<00:42, 146.28it/s]\u001b[A\n",
            " 52%|█████▏    | 6655/12815 [00:36<00:41, 148.14it/s]\u001b[A\n",
            " 52%|█████▏    | 6672/12815 [00:36<00:40, 149.98it/s]\u001b[A\n",
            " 52%|█████▏    | 6695/12815 [00:36<00:37, 162.75it/s]\u001b[A\n",
            " 52%|█████▏    | 6713/12815 [00:37<00:37, 163.77it/s]\u001b[A\n",
            " 53%|█████▎    | 6731/12815 [00:37<00:37, 162.58it/s]\u001b[A\n",
            " 53%|█████▎    | 6766/12815 [00:37<00:32, 186.88it/s]\u001b[A\n",
            " 53%|█████▎    | 6791/12815 [00:37<00:31, 193.18it/s]\u001b[A\n",
            " 53%|█████▎    | 6838/12815 [00:37<00:26, 228.85it/s]\u001b[A\n",
            " 54%|█████▎    | 6879/12815 [00:37<00:23, 252.88it/s]\u001b[A\n",
            " 54%|█████▍    | 6926/12815 [00:37<00:20, 283.79it/s]\u001b[A\n",
            " 54%|█████▍    | 6958/12815 [00:38<00:35, 167.19it/s]\u001b[A\n",
            " 54%|█████▍    | 6983/12815 [00:38<00:33, 176.09it/s]\u001b[A\n",
            " 55%|█████▍    | 7007/12815 [00:38<00:31, 181.85it/s]\u001b[A\n",
            " 55%|█████▍    | 7030/12815 [00:38<00:39, 148.13it/s]\u001b[A\n",
            " 55%|█████▌    | 7049/12815 [00:38<00:37, 152.45it/s]\u001b[A\n",
            " 55%|█████▌    | 7074/12815 [00:38<00:34, 167.78it/s]\u001b[A\n",
            " 55%|█████▌    | 7094/12815 [00:39<00:37, 152.40it/s]\u001b[A\n",
            " 56%|█████▌    | 7117/12815 [00:39<00:34, 166.13it/s]\u001b[A\n",
            " 56%|█████▌    | 7151/12815 [00:39<00:29, 193.99it/s]\u001b[A\n",
            " 56%|█████▌    | 7203/12815 [00:39<00:24, 228.70it/s]\u001b[A\n",
            " 56%|█████▋    | 7231/12815 [00:39<00:26, 209.94it/s]\u001b[A\n",
            " 57%|█████▋    | 7256/12815 [00:39<00:41, 133.74it/s]\u001b[A\n",
            " 57%|█████▋    | 7276/12815 [00:40<00:51, 107.32it/s]\u001b[A\n",
            " 57%|█████▋    | 7292/12815 [00:40<00:47, 116.21it/s]\u001b[A\n",
            " 57%|█████▋    | 7317/12815 [00:40<00:44, 122.67it/s]\u001b[A\n",
            " 57%|█████▋    | 7338/12815 [00:40<00:39, 137.87it/s]\u001b[A\n",
            " 57%|█████▋    | 7355/12815 [00:40<00:49, 109.81it/s]\u001b[A\n",
            " 58%|█████▊    | 7373/12815 [00:40<00:44, 121.14it/s]\u001b[A\n",
            " 58%|█████▊    | 7388/12815 [00:40<00:43, 124.74it/s]\u001b[A\n",
            " 58%|█████▊    | 7421/12815 [00:41<00:38, 141.37it/s]\u001b[A\n",
            " 58%|█████▊    | 7443/12815 [00:41<00:34, 156.04it/s]\u001b[A\n",
            " 58%|█████▊    | 7464/12815 [00:41<00:33, 159.82it/s]\u001b[A\n",
            " 59%|█████▊    | 7501/12815 [00:41<00:28, 188.70it/s]\u001b[A\n",
            " 59%|█████▊    | 7523/12815 [00:41<00:35, 151.15it/s]\u001b[A\n",
            " 59%|█████▉    | 7542/12815 [00:41<00:33, 156.63it/s]\u001b[A\n",
            " 59%|█████▉    | 7561/12815 [00:41<00:36, 142.36it/s]\u001b[A\n",
            " 59%|█████▉    | 7584/12815 [00:42<00:33, 156.19it/s]\u001b[A\n",
            " 59%|█████▉    | 7602/12815 [00:42<00:55, 93.75it/s] \u001b[A\n",
            " 60%|█████▉    | 7631/12815 [00:42<00:44, 116.31it/s]\u001b[A\n",
            " 60%|█████▉    | 7680/12815 [00:42<00:34, 148.12it/s]\u001b[A\n",
            " 60%|██████    | 7715/12815 [00:42<00:31, 162.43it/s]\u001b[A\n",
            " 60%|██████    | 7743/12815 [00:42<00:28, 179.12it/s]\u001b[A\n",
            " 61%|██████    | 7778/12815 [00:43<00:24, 204.22it/s]\u001b[A\n",
            " 61%|██████    | 7804/12815 [00:43<00:23, 212.90it/s]\u001b[A\n",
            " 61%|██████    | 7829/12815 [00:43<00:36, 136.96it/s]\u001b[A\n",
            " 61%|██████▏   | 7863/12815 [00:43<00:30, 161.79it/s]\u001b[A\n",
            " 62%|██████▏   | 7892/12815 [00:43<00:27, 180.54it/s]\u001b[A\n",
            " 62%|██████▏   | 7915/12815 [00:44<00:36, 133.25it/s]\u001b[A\n",
            " 62%|██████▏   | 7934/12815 [00:44<00:34, 142.05it/s]\u001b[A\n",
            " 62%|██████▏   | 7953/12815 [00:44<00:37, 130.50it/s]\u001b[A\n",
            " 62%|██████▏   | 7969/12815 [00:44<00:42, 114.71it/s]\u001b[A\n",
            " 62%|██████▏   | 8000/12815 [00:44<00:35, 136.79it/s]\u001b[A\n",
            " 63%|██████▎   | 8018/12815 [00:44<00:43, 111.35it/s]\u001b[A\n",
            " 63%|██████▎   | 8054/12815 [00:44<00:34, 138.69it/s]\u001b[A\n",
            " 63%|██████▎   | 8074/12815 [00:45<00:31, 148.37it/s]\u001b[A\n",
            " 63%|██████▎   | 8094/12815 [00:45<00:30, 154.35it/s]\u001b[A\n",
            " 63%|██████▎   | 8113/12815 [00:45<00:29, 157.08it/s]\u001b[A\n",
            " 64%|██████▎   | 8152/12815 [00:45<00:24, 186.84it/s]\u001b[A\n",
            " 64%|██████▍   | 8175/12815 [00:45<00:34, 134.34it/s]\u001b[A\n",
            " 64%|██████▍   | 8196/12815 [00:45<00:31, 146.20it/s]\u001b[A\n",
            " 64%|██████▍   | 8218/12815 [00:45<00:29, 157.30it/s]\u001b[A\n",
            " 64%|██████▍   | 8237/12815 [00:46<00:32, 139.69it/s]\u001b[A\n",
            " 65%|██████▍   | 8278/12815 [00:46<00:26, 169.38it/s]\u001b[A\n",
            " 65%|██████▍   | 8317/12815 [00:46<00:22, 200.15it/s]\u001b[A\n",
            " 65%|██████▌   | 8364/12815 [00:46<00:19, 234.04it/s]\u001b[A\n",
            " 66%|██████▌   | 8395/12815 [00:46<00:18, 240.38it/s]\u001b[A\n",
            " 66%|██████▌   | 8430/12815 [00:46<00:17, 253.13it/s]\u001b[A\n",
            " 66%|██████▌   | 8461/12815 [00:46<00:16, 256.87it/s]\u001b[A\n",
            " 66%|██████▋   | 8490/12815 [00:46<00:16, 256.31it/s]\u001b[A\n",
            " 66%|██████▋   | 8519/12815 [00:47<00:16, 254.57it/s]\u001b[A\n",
            " 67%|██████▋   | 8546/12815 [00:47<00:21, 196.26it/s]\u001b[A\n",
            " 67%|██████▋   | 8569/12815 [00:47<00:24, 174.00it/s]\u001b[A\n",
            " 67%|██████▋   | 8598/12815 [00:47<00:24, 170.13it/s]\u001b[A\n",
            " 67%|██████▋   | 8617/12815 [00:47<00:25, 163.42it/s]\u001b[A\n",
            " 67%|██████▋   | 8643/12815 [00:47<00:25, 162.91it/s]\u001b[A\n",
            " 68%|██████▊   | 8661/12815 [00:48<00:28, 143.75it/s]\u001b[A\n",
            " 68%|██████▊   | 8685/12815 [00:48<00:26, 157.90it/s]\u001b[A\n",
            " 68%|██████▊   | 8702/12815 [00:48<00:33, 122.97it/s]\u001b[A\n",
            " 68%|██████▊   | 8720/12815 [00:48<00:31, 131.74it/s]\u001b[A\n",
            " 68%|██████▊   | 8735/12815 [00:48<00:32, 126.72it/s]\u001b[A\n",
            " 68%|██████▊   | 8759/12815 [00:48<00:28, 142.94it/s]\u001b[A\n",
            " 69%|██████▊   | 8784/12815 [00:48<00:25, 158.50it/s]\u001b[A\n",
            " 69%|██████▉   | 8828/12815 [00:49<00:20, 191.65it/s]\u001b[A\n",
            " 69%|██████▉   | 8874/12815 [00:49<00:17, 226.15it/s]\u001b[A\n",
            " 69%|██████▉   | 8903/12815 [00:49<00:16, 234.47it/s]\u001b[A\n",
            " 70%|██████▉   | 8931/12815 [00:49<00:18, 208.55it/s]\u001b[A\n",
            " 70%|███████   | 8994/12815 [00:49<00:14, 255.61it/s]\u001b[A\n",
            " 70%|███████   | 9028/12815 [00:49<00:17, 211.77it/s]\u001b[A\n",
            " 71%|███████   | 9056/12815 [00:49<00:16, 223.21it/s]\u001b[A\n",
            " 71%|███████   | 9084/12815 [00:49<00:16, 232.19it/s]\u001b[A\n",
            " 71%|███████   | 9111/12815 [00:50<00:15, 234.13it/s]\u001b[A\n",
            " 71%|███████▏  | 9137/12815 [00:50<00:15, 230.46it/s]\u001b[A\n",
            " 71%|███████▏  | 9162/12815 [00:50<00:16, 224.00it/s]\u001b[A\n",
            " 72%|███████▏  | 9186/12815 [00:50<00:16, 218.42it/s]\u001b[A\n",
            " 72%|███████▏  | 9209/12815 [00:50<00:19, 189.27it/s]\u001b[A\n",
            " 72%|███████▏  | 9230/12815 [00:50<00:19, 181.26it/s]\u001b[A\n",
            " 72%|███████▏  | 9258/12815 [00:50<00:18, 196.47it/s]\u001b[A\n",
            " 72%|███████▏  | 9279/12815 [00:50<00:18, 196.04it/s]\u001b[A\n",
            " 73%|███████▎  | 9300/12815 [00:51<00:18, 192.22it/s]\u001b[A\n",
            " 73%|███████▎  | 9320/12815 [00:51<00:18, 185.44it/s]\u001b[A\n",
            " 73%|███████▎  | 9339/12815 [00:51<00:24, 140.74it/s]\u001b[A\n",
            " 73%|███████▎  | 9369/12815 [00:51<00:20, 164.17it/s]\u001b[A\n",
            " 73%|███████▎  | 9395/12815 [00:51<00:19, 179.20it/s]\u001b[A\n",
            " 73%|███████▎  | 9416/12815 [00:51<00:22, 154.41it/s]\u001b[A\n",
            " 74%|███████▎  | 9434/12815 [00:52<00:26, 125.96it/s]\u001b[A\n",
            " 74%|███████▍  | 9472/12815 [00:52<00:21, 155.21it/s]\u001b[A\n",
            " 74%|███████▍  | 9502/12815 [00:52<00:18, 178.40it/s]\u001b[A\n",
            " 74%|███████▍  | 9525/12815 [00:52<00:17, 186.60it/s]\u001b[A\n",
            " 75%|███████▍  | 9554/12815 [00:52<00:16, 202.78it/s]\u001b[A\n",
            " 75%|███████▍  | 9578/12815 [00:52<00:19, 165.98it/s]\u001b[A\n",
            " 75%|███████▌  | 9623/12815 [00:52<00:16, 195.55it/s]\u001b[A\n",
            " 75%|███████▌  | 9647/12815 [00:52<00:17, 179.19it/s]\u001b[A\n",
            " 75%|███████▌  | 9669/12815 [00:53<00:23, 132.73it/s]\u001b[A\n",
            " 76%|███████▌  | 9694/12815 [00:53<00:20, 149.21it/s]\u001b[A\n",
            " 76%|███████▌  | 9723/12815 [00:53<00:18, 168.94it/s]\u001b[A\n",
            " 76%|███████▌  | 9764/12815 [00:53<00:15, 199.95it/s]\u001b[A\n",
            " 76%|███████▋  | 9789/12815 [00:53<00:22, 133.88it/s]\u001b[A\n",
            " 77%|███████▋  | 9850/12815 [00:54<00:17, 172.11it/s]\u001b[A\n",
            " 77%|███████▋  | 9880/12815 [00:54<00:16, 174.41it/s]\u001b[A\n",
            " 77%|███████▋  | 9906/12815 [00:54<00:19, 152.55it/s]\u001b[A\n",
            " 77%|███████▋  | 9928/12815 [00:54<00:19, 148.85it/s]\u001b[A\n",
            " 78%|███████▊  | 9948/12815 [00:54<00:23, 123.02it/s]\u001b[A\n",
            " 78%|███████▊  | 9965/12815 [00:54<00:24, 118.12it/s]\u001b[A\n",
            " 78%|███████▊  | 9996/12815 [00:55<00:19, 143.12it/s]\u001b[A\n",
            " 78%|███████▊  | 10022/12815 [00:55<00:17, 160.52it/s]\u001b[A\n",
            " 78%|███████▊  | 10044/12815 [00:55<00:16, 168.02it/s]\u001b[A\n",
            " 79%|███████▊  | 10064/12815 [00:55<00:16, 168.67it/s]\u001b[A\n",
            " 79%|███████▉  | 10099/12815 [00:55<00:13, 194.33it/s]\u001b[A\n",
            " 79%|███████▉  | 10132/12815 [00:55<00:14, 191.63it/s]\u001b[A\n",
            " 79%|███████▉  | 10154/12815 [00:55<00:19, 135.06it/s]\u001b[A\n",
            " 79%|███████▉  | 10173/12815 [00:56<00:18, 146.23it/s]\u001b[A\n",
            " 80%|███████▉  | 10218/12815 [00:56<00:14, 179.04it/s]\u001b[A\n",
            " 80%|███████▉  | 10243/12815 [00:56<00:13, 190.11it/s]\u001b[A\n",
            " 80%|████████  | 10269/12815 [00:56<00:12, 200.51it/s]\u001b[A\n",
            " 80%|████████  | 10296/12815 [00:56<00:11, 212.01it/s]\u001b[A\n",
            " 81%|████████  | 10333/12815 [00:56<00:10, 234.25it/s]\u001b[A\n",
            " 81%|████████  | 10359/12815 [00:56<00:13, 179.12it/s]\u001b[A\n",
            " 81%|████████  | 10390/12815 [00:56<00:12, 200.06it/s]\u001b[A\n",
            " 81%|████████▏ | 10414/12815 [00:57<00:13, 180.77it/s]\u001b[A\n",
            " 81%|████████▏ | 10435/12815 [00:57<00:18, 131.75it/s]\u001b[A\n",
            " 82%|████████▏ | 10466/12815 [00:57<00:14, 157.28it/s]\u001b[A\n",
            " 82%|████████▏ | 10487/12815 [00:57<00:17, 132.95it/s]\u001b[A\n",
            " 82%|████████▏ | 10506/12815 [00:57<00:18, 124.16it/s]\u001b[A\n",
            " 82%|████████▏ | 10522/12815 [00:58<00:17, 131.38it/s]\u001b[A\n",
            " 82%|████████▏ | 10546/12815 [00:58<00:15, 149.42it/s]\u001b[A\n",
            " 83%|████████▎ | 10616/12815 [00:58<00:11, 191.93it/s]\u001b[A\n",
            " 83%|████████▎ | 10646/12815 [00:58<00:13, 160.00it/s]\u001b[A\n",
            " 83%|████████▎ | 10670/12815 [00:58<00:13, 154.78it/s]\u001b[A\n",
            " 84%|████████▎ | 10715/12815 [00:58<00:11, 187.52it/s]\u001b[A\n",
            " 84%|████████▍ | 10741/12815 [00:58<00:11, 174.06it/s]\u001b[A\n",
            " 84%|████████▍ | 10764/12815 [00:59<00:11, 183.88it/s]\u001b[A\n",
            " 84%|████████▍ | 10787/12815 [00:59<00:13, 151.12it/s]\u001b[A\n",
            " 84%|████████▍ | 10827/12815 [00:59<00:10, 181.50it/s]\u001b[A\n",
            " 85%|████████▍ | 10851/12815 [00:59<00:12, 153.90it/s]\u001b[A\n",
            " 85%|████████▍ | 10871/12815 [00:59<00:12, 160.14it/s]\u001b[A\n",
            " 85%|████████▌ | 10897/12815 [00:59<00:10, 175.05it/s]\u001b[A\n",
            " 85%|████████▌ | 10923/12815 [00:59<00:10, 182.80it/s]\u001b[A\n",
            " 86%|████████▌ | 10958/12815 [01:00<00:08, 209.08it/s]\u001b[A\n",
            " 86%|████████▌ | 10984/12815 [01:00<00:08, 215.57it/s]\u001b[A\n",
            " 86%|████████▌ | 11008/12815 [01:00<00:09, 187.54it/s]\u001b[A\n",
            " 86%|████████▌ | 11029/12815 [01:00<00:10, 166.85it/s]\u001b[A\n",
            " 86%|████████▋ | 11053/12815 [01:00<00:10, 161.09it/s]\u001b[A\n",
            " 86%|████████▋ | 11077/12815 [01:00<00:10, 172.46it/s]\u001b[A\n",
            " 87%|████████▋ | 11096/12815 [01:00<00:10, 171.31it/s]\u001b[A\n",
            " 87%|████████▋ | 11125/12815 [01:01<00:09, 173.00it/s]\u001b[A\n",
            " 87%|████████▋ | 11143/12815 [01:01<00:09, 168.91it/s]\u001b[A\n",
            " 87%|████████▋ | 11191/12815 [01:01<00:07, 204.91it/s]\u001b[A\n",
            " 88%|████████▊ | 11216/12815 [01:01<00:07, 207.86it/s]\u001b[A\n",
            " 88%|████████▊ | 11240/12815 [01:01<00:07, 211.11it/s]\u001b[A\n",
            " 88%|████████▊ | 11275/12815 [01:01<00:06, 232.05it/s]\u001b[A\n",
            " 88%|████████▊ | 11301/12815 [01:01<00:06, 228.56it/s]\u001b[A\n",
            " 88%|████████▊ | 11328/12815 [01:01<00:06, 229.59it/s]\u001b[A\n",
            " 89%|████████▊ | 11352/12815 [01:02<00:06, 217.47it/s]\u001b[A\n",
            " 89%|████████▉ | 11385/12815 [01:02<00:06, 234.47it/s]\u001b[A\n",
            " 89%|████████▉ | 11410/12815 [01:02<00:07, 180.76it/s]\u001b[A\n",
            " 89%|████████▉ | 11431/12815 [01:02<00:08, 159.59it/s]\u001b[A\n",
            " 89%|████████▉ | 11451/12815 [01:02<00:08, 164.90it/s]\u001b[A\n",
            " 90%|████████▉ | 11482/12815 [01:02<00:07, 184.78it/s]\u001b[A\n",
            " 90%|████████▉ | 11503/12815 [01:02<00:08, 163.58it/s]\u001b[A\n",
            " 90%|████████▉ | 11530/12815 [01:03<00:07, 177.78it/s]\u001b[A\n",
            " 90%|█████████ | 11550/12815 [01:03<00:07, 177.59it/s]\u001b[A\n",
            " 90%|█████████ | 11574/12815 [01:03<00:06, 187.51it/s]\u001b[A\n",
            " 91%|█████████ | 11613/12815 [01:03<00:05, 214.14it/s]\u001b[A\n",
            " 91%|█████████ | 11637/12815 [01:03<00:09, 127.86it/s]\u001b[A\n",
            " 91%|█████████ | 11677/12815 [01:03<00:07, 157.29it/s]\u001b[A\n",
            " 91%|█████████▏| 11701/12815 [01:03<00:06, 171.42it/s]\u001b[A\n",
            " 92%|█████████▏| 11746/12815 [01:04<00:05, 200.20it/s]\u001b[A\n",
            " 92%|█████████▏| 11778/12815 [01:04<00:04, 218.47it/s]\u001b[A\n",
            " 92%|█████████▏| 11814/12815 [01:04<00:04, 237.40it/s]\u001b[A\n",
            " 92%|█████████▏| 11846/12815 [01:04<00:03, 249.95it/s]\u001b[A\n",
            " 93%|█████████▎| 11874/12815 [01:04<00:04, 218.76it/s]\u001b[A\n",
            " 93%|█████████▎| 11899/12815 [01:04<00:04, 218.49it/s]\u001b[A\n",
            " 93%|█████████▎| 11923/12815 [01:04<00:04, 214.36it/s]\u001b[A\n",
            " 93%|█████████▎| 11946/12815 [01:04<00:04, 207.91it/s]\u001b[A\n",
            " 93%|█████████▎| 11968/12815 [01:05<00:05, 158.52it/s]\u001b[A\n",
            " 94%|█████████▎| 11995/12815 [01:05<00:04, 177.12it/s]\u001b[A\n",
            " 94%|█████████▍| 12045/12815 [01:05<00:03, 200.70it/s]\u001b[A\n",
            " 94%|█████████▍| 12068/12815 [01:05<00:04, 157.82it/s]\u001b[A\n",
            " 94%|█████████▍| 12088/12815 [01:05<00:05, 144.02it/s]\u001b[A\n",
            " 94%|█████████▍| 12108/12815 [01:05<00:04, 152.11it/s]\u001b[A\n",
            " 95%|█████████▍| 12126/12815 [01:06<00:05, 119.15it/s]\u001b[A\n",
            " 95%|█████████▍| 12155/12815 [01:06<00:04, 141.70it/s]\u001b[A\n",
            " 95%|█████████▍| 12173/12815 [01:06<00:04, 128.92it/s]\u001b[A\n",
            " 95%|█████████▌| 12189/12815 [01:06<00:05, 116.89it/s]\u001b[A\n",
            " 95%|█████████▌| 12212/12815 [01:06<00:04, 132.14it/s]\u001b[A\n",
            " 95%|█████████▌| 12228/12815 [01:06<00:04, 134.55it/s]\u001b[A\n",
            " 96%|█████████▌| 12248/12815 [01:06<00:03, 144.27it/s]\u001b[A\n",
            " 96%|█████████▌| 12283/12815 [01:07<00:03, 170.07it/s]\u001b[A\n",
            " 96%|█████████▌| 12303/12815 [01:07<00:03, 151.52it/s]\u001b[A\n",
            " 96%|█████████▌| 12321/12815 [01:07<00:03, 151.56it/s]\u001b[A\n",
            " 96%|█████████▋| 12363/12815 [01:07<00:02, 183.25it/s]\u001b[A\n",
            " 97%|█████████▋| 12412/12815 [01:07<00:01, 218.59it/s]\u001b[A\n",
            " 97%|█████████▋| 12440/12815 [01:07<00:02, 180.93it/s]\u001b[A\n",
            " 97%|█████████▋| 12464/12815 [01:08<00:02, 166.45it/s]\u001b[A\n",
            " 98%|█████████▊| 12501/12815 [01:08<00:01, 193.55it/s]\u001b[A\n",
            " 98%|█████████▊| 12525/12815 [01:08<00:01, 190.30it/s]\u001b[A\n",
            " 98%|█████████▊| 12548/12815 [01:08<00:01, 139.45it/s]\u001b[A\n",
            " 98%|█████████▊| 12583/12815 [01:08<00:01, 165.01it/s]\u001b[A\n",
            " 98%|█████████▊| 12605/12815 [01:08<00:01, 151.23it/s]\u001b[A\n",
            " 99%|█████████▊| 12636/12815 [01:08<00:01, 162.33it/s]\u001b[A\n",
            " 99%|█████████▉| 12657/12815 [01:09<00:01, 149.13it/s]\u001b[A\n",
            " 99%|█████████▉| 12683/12815 [01:09<00:00, 162.46it/s]\u001b[A\n",
            " 99%|█████████▉| 12702/12815 [01:09<00:00, 127.03it/s]\u001b[A\n",
            " 99%|█████████▉| 12718/12815 [01:09<00:00, 130.55it/s]\u001b[A\n",
            " 99%|█████████▉| 12733/12815 [01:09<00:00, 127.81it/s]\u001b[A\n",
            " 99%|█████████▉| 12748/12815 [01:09<00:00, 127.75it/s]\u001b[A\n",
            "100%|█████████▉| 12762/12815 [01:10<00:00, 99.14it/s] \u001b[A\n",
            "100%|█████████▉| 12774/12815 [01:10<00:00, 101.66it/s]\u001b[A\n",
            "100%|█████████▉| 12786/12815 [01:10<00:00, 99.56it/s] \u001b[A\n",
            "100%|██████████| 12815/12815 [01:10<00:00, 182.20it/s]\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "uSv12HoaxbPA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ans.to_csv('answer.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HjvMpqiGx7Vr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}